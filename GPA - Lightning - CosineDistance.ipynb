{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "from transformers import Adafactor\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "from sklearn import metrics\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import logging\n",
    "from util import *\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "import pprint\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import util\n",
    "#from catalyst.metrics.functional import process_multilabel_components\n",
    "#from catalyst.metrics import multi_label_accuracy\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.core.decorators import auto_move_data\n",
    "from sklearn.metrics import label_ranking_average_precision_score, accuracy_score, f1_score\n",
    "#from ignite.utils import convert_tensor\n",
    "#from pytorch_metric_learning.miners import MultiSimilarityMiner\n",
    "#from pytorch_metric_learning.losses import TripletMarginLoss\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset=list(sorted(set(all_tiers_100)-set([\"PersonalizedProduct\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import funcy as f\n",
    "from random import shuffle\n",
    "\n",
    "@f.collecting\n",
    "def create_examples(row, num_neg=2):\n",
    "    abstract = row.abstract\n",
    "    claims = row.claims\n",
    "    yield (abstract, claims, True)\n",
    "    for text in [abstract,claims]:\n",
    "        neg_count = 0\n",
    "        shuffle(subset)\n",
    "        for tag in subset:\n",
    "            if row[tag]:\n",
    "                yield (text, f\"Tagged as {tier_translations[tag]}.\", True)\n",
    "            elif num_neg is None or neg_count < num_neg:\n",
    "                neg_count = neg_count + 1\n",
    "                yield (text, f\"Tagged as {tier_translations[tag]}.\", False)\n",
    "            else:\n",
    "                continue\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatentDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, abstract_max_len=160, claims_max_len=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.claims_max_len = claims_max_len\n",
    "        self.abstract_max_len = abstract_max_len\n",
    "\n",
    "        self.claims = dataframe.claims\n",
    "        self.abstracts = dataframe.abstract        \n",
    "        self.labels = dataframe.labels\n",
    "        \n",
    "    def tokenize(self, text, max_len):\n",
    "        text = str(text)\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        return {\n",
    "            f\"input_ids\": torch.tensor(ids, dtype=torch.long),\n",
    "            f\"attention_mask\": torch.tensor(mask, dtype=torch.long),\n",
    "            f\"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        abstract = self.tokenize(self.abstracts[index], max_len=self.abstract_max_len)\n",
    "        claims = self.tokenize(self.claims[index], max_len=self.claims_max_len)\n",
    "        #embedded_cpc = torch.tensor(np.array(self.data.embedded_cpc[index]), dtype=torch.float)\n",
    "        \n",
    "        labels = torch.tensor(self.labels[index])\n",
    "        return {\"abstract\": abstract, \n",
    "                \"claims\": claims,\n",
    "                #'embedded_cpc': embedded_cpc,\n",
    "                'labels': labels}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bertForPatents/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def linear_combination(x, y, epsilon): \n",
    "    return epsilon*x + (1-epsilon)*y\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, pos_weights, epsilon:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.reduction = reduction\n",
    "        self.pos_weights = pos_weights\n",
    "    \n",
    "    def forward(self, preds, target):\n",
    "        n = preds.size()[-1]\n",
    "        #log_preds = F.log_softmax(preds, dim=-1)\n",
    "        loss = reduce_loss(-preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.binary_cross_entropy_with_logits(preds, target, pos_weight=self.pos_weights.to(\"cuda:0\"), reduction=self.reduction)\n",
    "        return linear_combination(loss/n, nll, self.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.metrics import functional as FM\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\" Set all seeds to make results reproducible \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "class BasicSystem(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                     batch_size=8, \n",
    "                     internal_embedding_size=512, \n",
    "                     classifier_dropout=0,\n",
    "                     preclassifier_size = 256,\n",
    "                     preclassifier_dropout = 0,\n",
    "                     embedding_dropout= 0.2,\n",
    "                     lr_warmup_steps=200,\n",
    "                     model_name=\"bertForPatents/\", \n",
    "                     gradient_checkpointing=True, \n",
    "                     learning_rate = 5e-6,\n",
    "                     seed=42,\n",
    "                     ):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.subset = subset\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.preclassifier_dropout = preclassifier_dropout\n",
    "        self.preclassifier_size = preclassifier_size\n",
    "        self.classifier_dropout = classifier_dropout\n",
    "        self.embedding_dropout = embedding_dropout\n",
    "        self.internal_embedding_size = internal_embedding_size\n",
    "        self.gradient_checkpointing = gradient_checkpointing\n",
    "        if seed:\n",
    "            set_seed(seed)\n",
    "        self.lr_warmup_steps = lr_warmup_steps\n",
    "        \n",
    "        \n",
    "    def prepare_data(self):\n",
    "        self.training_set = pd.read_json(\"training_set.json.gz\", lines=True, orient=\"records\")\n",
    "        self.testing_set = pd.read_json(\"testing_set.json.gz\", lines=True, orient=\"records\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        \n",
    "#         self.cpc_embeddings = np.fromfile(\"/home/martin/patentmark/cpc.node2vec.emb.32d.bin\", dtype=np.float32).reshape((-1,32))\n",
    "#         self.cpc_labelizer = joblib.load('./node2id.joblib')\n",
    "#         self.cpc_lookup = {c: n for n, c in enumerate(self.cpc_labelizer.classes_)}\n",
    "       \n",
    "    @f.collecting\n",
    "    def convert_cpc_codes(self, codes):\n",
    "        for code in codes:\n",
    "            if code in self.cpc_lookup:\n",
    "                yield self.cpc_lookup[code]\n",
    "    \n",
    "    def embed_cpc_codes(self,codes):\n",
    "        embedding = np.zeros(32)\n",
    "        converted = self.convert_cpc_codes(codes)\n",
    "\n",
    "        if not converted:\n",
    "            return embedding\n",
    "\n",
    "        for code_id in converted:\n",
    "            embedding = embedding + self.cpc_embeddings[code_id]\n",
    "\n",
    "        return embedding / len(converted)\n",
    "    \n",
    "    def tokenize_tags(self, tags):\n",
    "        return tokenizer.batch_encode_plus(tags, None, truncation=True, max_length=512, pad_to_max_length=True, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "    \n",
    "        \n",
    "    def setup(self,stage):\n",
    "\n",
    "        training_labels = self.training_set[self.subset].apply(util.array_labels, axis=1)\n",
    "        testing_labels = self.testing_set[self.subset].apply(util.array_labels, axis=1)\n",
    "        all_labels = np.concatenate((training_labels, testing_labels))\n",
    "        \n",
    "        self.label_encoder = MultiLabelBinarizer(sparse_output=False)\n",
    "        self.label_encoder.fit(all_labels)\n",
    "        self.output_size = len(self.label_encoder.classes_)\n",
    "\n",
    "        self.tags_tokenized = self.tokenize_tags([f\"Tagged as {x}.\" for x in self.label_encoder.classes_])\n",
    "        \n",
    "        enc_train_labels = self.label_encoder.transform(training_labels)\n",
    "        enc_test_labels = self.label_encoder.transform(testing_labels)\n",
    "               \n",
    "        self.training_set['labels'] = enc_train_labels.tolist() #.astype(np.float).tolist()\n",
    "        self.testing_set['labels'] = enc_test_labels.tolist() #self.label_encoder.transform(testing_labels).astype(np.float).tolist()\n",
    "        \n",
    "        #self.training_set['embedded_cpc'] = self.training_set.cpc_codes.apply(self.embed_cpc_codes)\n",
    "        #self.testing_set['embedded_cpc'] = self.testing_set.cpc_codes.apply(self.embed_cpc_codes)\n",
    "        \n",
    "        \n",
    "        self.training_dataset = PatentDataset(self.training_set, self.tokenizer)\n",
    "               \n",
    "        self.testing_dataset = PatentDataset(self.testing_set, self.tokenizer)\n",
    "        \n",
    "        self.setup_embedder()\n",
    "        self.setup_classifier()\n",
    "        \n",
    "        \n",
    "    def setup_embedder(self):\n",
    "        self.text_embedder = AutoModel.from_pretrained(self.model_name, gradient_checkpointing=self.gradient_checkpointing)\n",
    "#         for param in self.text_embedder.base_model.parameters():\n",
    "#             param.requires_grad=False\n",
    "            \n",
    "        self.embedding_size = 1024\n",
    "        self.embedding_dropout_layer = nn.Dropout(self.embedding_dropout)\n",
    "        self.embedding_layer = nn.Linear(self.embedding_size*2, self.embedding_size)\n",
    "        \n",
    "        \n",
    "    def setup_classifier(self):\n",
    "        self.classifier_layer = nn.Linear(self.embedding_size * 2, self.output_size)\n",
    "        pos_weights = torch.tensor(1 / (self.training_set[self.subset].sum() / self.training_set.shape[0]).values).to('cuda:0')\n",
    "        \n",
    "    def get_tag_embeddings(self):\n",
    "        return self.text_embedder(**self.tags_tokenized)[1]\n",
    "\n",
    "    \n",
    "    def classify_patent(self, abstract, claims, ):\n",
    "        abstract_emb = self.text_embedder(input_ids=abstract[\"input_ids\"], attention_mask=abstract[\"attention_mask\"])\n",
    "        abstract_emb = abstract_emb[1]\n",
    "        \n",
    "        claim_emb = self.text_embedder(input_ids=claims[\"input_ids\"], attention_mask=claims[\"attention_mask\"])\n",
    "        claim_emb = claim_emb[1]\n",
    "        \n",
    "        x = torch.cat((abstract_emb, claim_emb), 1)\n",
    "        #x = claim_emb\n",
    "        \n",
    "        if self.embedding_dropout > 0:\n",
    "            x = self.embedding_dropout_layer(x)\n",
    "           \n",
    "        x = F.relu(x)\n",
    "        x= self.embedding_layer(x)\n",
    "        \n",
    "        \n",
    "        patent_emb = x.reshape(-1, 1, 1024)\n",
    "        #self.embedding_layer(x).reshape(self.batch_size, 1, 1024) #.expand(self.batch_size, 1, 1024)\n",
    "        #print(f\"patent_emb: {patent_emb.shape}\")\n",
    "        \n",
    "        tag_embeddings = self.get_tag_embeddings().reshape(1, 22, 1024)\n",
    "        #print(f\"tag_embeddings: {tag_embeddings.shape}\")\n",
    "        \n",
    "        #distances = torch.nn.CosineSimilarity(dim=2)(patent_emb, tag_embeddings)\n",
    "        #print(f\"distances: {distances.shape}\")\n",
    "        \n",
    "        return patent_emb, tag_embeddings\n",
    "    \n",
    "#     @auto_move_data\n",
    "#     def get_loss_function(self, pos_weights):\n",
    "#         #return nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "#         #return LabelSmoothingCrossEntropy(pos_weights)\n",
    "    \n",
    "    @auto_move_data\n",
    "    def forward(self, abstract, claims):\n",
    "        patent_emb, tag_embeddings = self.classify_patent(abstract, claims)\n",
    "\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.training_dataset, batch_size=self.batch_size, shuffle=True, num_workers=32)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.testing_dataset, batch_size=self.batch_size, shuffle=False, num_workers=32)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.val_dataloader()\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "                \n",
    "        abstract = batch['abstract']\n",
    "        claims = batch['claims']\n",
    "        #embedded_cpc = batch['embedded_cpc']\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        patent_emb, tag_embeddings = self.classify_patent(abstract, claims)\n",
    "        distances = torch.nn.CosineSimilarity(dim=2)(patent_emb, tag_embeddings)\n",
    "        \n",
    "        loss = nn.MSELoss()(distances, labels.float())\n",
    "        #loss = nn.CosineEmbeddingLoss(margin=0.5)(patent_emb, tag_embeddings, labels)\n",
    "        \n",
    "        #self.loss_function(logits.squeeze(-1), labels.float()) #@* self.ratio\n",
    "     \n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    " \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        abstract = batch['abstract']\n",
    "        claims = batch['claims']\n",
    "#        embedded_cpc = batch['embedded_cpc']\n",
    "        labels = batch['labels']\n",
    "       \n",
    "        patent_emb, tag_embeddings = self.classify_patent(abstract, claims)\n",
    "        distances = torch.nn.CosineSimilarity(dim=2)(patent_emb, tag_embeddings)\n",
    "        loss = nn.MSELoss()(distances, labels.float())\n",
    "        \n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "            \n",
    "        predictions = (distances.cpu().detach().numpy() >= 0.5)\n",
    "        \n",
    "#         print(\"patent\", patent_emb.shape)\n",
    "#         print(\"tag\", tag_embeddings.shape)\n",
    "#         print(\"labels\", labels.shape)\n",
    "#         print(\"distances\", distances.shape)\n",
    "#         print(\"predictions\", predictions.shape)\n",
    "\n",
    "        predictions = predictions.tolist()\n",
    "        labels = labels.cpu().detach().numpy().astype(np.bool).tolist()\n",
    "        \n",
    "        return predictions, labels\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        predictions = list(f.cat(x[0] for x in outputs))\n",
    "        labels = list(f.cat(x[1] for x in outputs))\n",
    "        self.log(\"val_f1\", f1_score(labels, predictions, average=\"samples\"), prog_bar=True)\n",
    "        print(classification_report(labels, predictions, target_names=self.label_encoder.classes_, digits=4))\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        #return Adafactor(self.parameters(), lr=0.001, scale_parameter=False, relative_step=False)\n",
    "        #return torch.optim.SGD(self.parameters(), lr=self.learning_rate)  #AdamW(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "2020-12-14 07:56:01 - GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "2020-12-14 07:56:01 - TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2020-12-14 07:56:01 - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "model = BasicSystem()\n",
    "#early_stopping = EarlyStopping('val_f1', mode=\"max\", verbose=True, patience=10)\n",
    "#early_stopping = EarlyStopping('loss', mode=\"min\", verbose=True, patience=3)\n",
    "trainer = pl.Trainer(gpus=1,\n",
    "                     #overfit_batches=5,\n",
    " #                    callbacks=[early_stopping],\n",
    "                     #precision=16,\n",
    "                     #auto_scale_batch_size=True,\n",
    "                     #auto_lr_find=True,\n",
    "                     #accumulate_grad_batches=4,\n",
    "                     log_every_n_steps=1,\n",
    "                     #val_check_interval=100000,\n",
    "                     #limit_val_batches=0.0,\n",
    "                     flush_logs_every_n_steps=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.tune(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                    | Type      | Params\n",
      "------------------------------------------------------\n",
      "0 | text_embedder           | BertModel | 344 M \n",
      "1 | embedding_dropout_layer | Dropout   | 0     \n",
      "2 | embedding_layer         | Linear    | 2 M   \n",
      "3 | classifier_layer        | Linear    | 45 K  \n",
      "2020-12-14 07:56:12 - \n",
      "  | Name                    | Type      | Params\n",
      "------------------------------------------------------\n",
      "0 | text_embedder           | BertModel | 344 M \n",
      "1 | embedding_dropout_layer | Dropout   | 0     \n",
      "2 | embedding_layer         | Linear    | 2 M   \n",
      "3 | classifier_layer        | Linear    | 45 K  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               precision    recall  f1-score   support\n",
      "\n",
      "                        Analysis and Modeling     0.0000    0.0000    0.0000         6\n",
      "           Analysis and Modeling: 3D Modeling     0.0000    0.0000    0.0000         4\n",
      "                            Anatomical Target     0.0000    0.0000    0.0000        13\n",
      "           Anatomical Target: Lower Extremity     0.0000    0.0000    0.0000         9\n",
      "     Anatomical Target: Lower Extremity - Hip     0.0000    0.0000    0.0000         4\n",
      "    Anatomical Target: Lower Extremity - Knee     0.0000    0.0000    0.0000         4\n",
      "                     Anatomical Target: Torso     0.0000    0.0000    0.0000         1\n",
      "             Anatomical Target: Torso - Spine     0.0000    0.0000    0.0000         0\n",
      "           Anatomical Target: Upper Extremity     0.0000    0.0000    0.0000         2\n",
      "Anatomical Target: Upper Extremity - Shoulder     0.0000    0.0000    0.0000         2\n",
      "                                      Imaging     0.0000    0.0000    0.0000         8\n",
      "                                  Imaging: CT     0.0000    0.0000    0.0000         3\n",
      "                                 Imaging: MRI     0.0000    0.0000    0.0000         3\n",
      "                          Imaging: Ultrasound     0.0000    0.0000    0.0000         2\n",
      "                                Manufacturing     0.0000    0.0000    0.0000         6\n",
      "        Manufacturing: Additive Manufacturing     0.0000    0.0000    0.0000         0\n",
      "           Personalized Product: Guide or Jig     0.0000    0.0000    0.0000         8\n",
      "                Personalized Product: Implant     0.0000    0.0000    0.0000         8\n",
      "                         Specification of Use     0.0000    0.0000    0.0000         3\n",
      "                Specification of Use: Disease     0.0000    0.0000    0.0000         2\n",
      "      Specification of Use: Joint Replacement     0.0000    0.0000    0.0000         1\n",
      "                              Surgical Method     0.0000    0.0000    0.0000         3\n",
      "\n",
      "                                    micro avg     0.0000    0.0000    0.0000        92\n",
      "                                    macro avg     0.0000    0.0000    0.0000        92\n",
      "                                 weighted avg     0.0000    0.0000    0.0000        92\n",
      "                                  samples avg     0.0000    0.0000    0.0000        92\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75985560d7e14539aa75b79b9df25ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               precision    recall  f1-score   support\n",
      "\n",
      "                        Analysis and Modeling     0.0000    0.0000    0.0000        84\n",
      "           Analysis and Modeling: 3D Modeling     0.0000    0.0000    0.0000        71\n",
      "                            Anatomical Target     0.6749    1.0000    0.8059       164\n",
      "           Anatomical Target: Lower Extremity     0.0000    0.0000    0.0000       113\n",
      "     Anatomical Target: Lower Extremity - Hip     0.0000    0.0000    0.0000        40\n",
      "    Anatomical Target: Lower Extremity - Knee     0.0000    0.0000    0.0000        82\n",
      "                     Anatomical Target: Torso     0.0000    0.0000    0.0000        35\n",
      "             Anatomical Target: Torso - Spine     0.0000    0.0000    0.0000        21\n",
      "           Anatomical Target: Upper Extremity     0.0000    0.0000    0.0000        31\n",
      "Anatomical Target: Upper Extremity - Shoulder     0.0000    0.0000    0.0000        23\n",
      "                                      Imaging     0.5473    1.0000    0.7074       133\n",
      "                                  Imaging: CT     0.0000    0.0000    0.0000        59\n",
      "                                 Imaging: MRI     0.0000    0.0000    0.0000        59\n",
      "                          Imaging: Ultrasound     0.0000    0.0000    0.0000        32\n",
      "                                Manufacturing     0.3444    1.0000    0.5123        83\n",
      "        Manufacturing: Additive Manufacturing     0.0000    0.0000    0.0000        38\n",
      "           Personalized Product: Guide or Jig     0.4516    0.1167    0.1854       120\n",
      "                Personalized Product: Implant     0.5083    0.9919    0.6721       124\n",
      "                         Specification of Use     0.0000    0.0000    0.0000        79\n",
      "                Specification of Use: Disease     0.0000    0.0000    0.0000        30\n",
      "      Specification of Use: Joint Replacement     0.0000    0.0000    0.0000        44\n",
      "                              Surgical Method     0.0000    0.0000    0.0000        40\n",
      "\n",
      "                                    micro avg     0.5170    0.3435    0.4128      1505\n",
      "                                    macro avg     0.1148    0.1868    0.1311      1505\n",
      "                                 weighted avg     0.2188    0.3435    0.2488      1505\n",
      "                                  samples avg     0.5200    0.3816    0.4116      1505\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               precision    recall  f1-score   support\n",
      "\n",
      "                        Analysis and Modeling     0.0000    0.0000    0.0000        84\n",
      "           Analysis and Modeling: 3D Modeling     0.0000    0.0000    0.0000        71\n",
      "                            Anatomical Target     0.6749    1.0000    0.8059       164\n",
      "           Anatomical Target: Lower Extremity     0.0000    0.0000    0.0000       113\n",
      "     Anatomical Target: Lower Extremity - Hip     0.0000    0.0000    0.0000        40\n",
      "    Anatomical Target: Lower Extremity - Knee     0.0000    0.0000    0.0000        82\n",
      "                     Anatomical Target: Torso     0.0000    0.0000    0.0000        35\n",
      "             Anatomical Target: Torso - Spine     0.0000    0.0000    0.0000        21\n",
      "           Anatomical Target: Upper Extremity     0.0000    0.0000    0.0000        31\n",
      "Anatomical Target: Upper Extremity - Shoulder     0.0000    0.0000    0.0000        23\n",
      "                                      Imaging     0.5473    1.0000    0.7074       133\n",
      "                                  Imaging: CT     0.0000    0.0000    0.0000        59\n",
      "                                 Imaging: MRI     0.0000    0.0000    0.0000        59\n",
      "                          Imaging: Ultrasound     0.0000    0.0000    0.0000        32\n",
      "                                Manufacturing     0.0000    0.0000    0.0000        83\n",
      "        Manufacturing: Additive Manufacturing     0.0000    0.0000    0.0000        38\n",
      "           Personalized Product: Guide or Jig     0.0000    0.0000    0.0000       120\n",
      "                Personalized Product: Implant     0.5103    1.0000    0.6757       124\n",
      "                         Specification of Use     0.0000    0.0000    0.0000        79\n",
      "                Specification of Use: Disease     0.0000    0.0000    0.0000        30\n",
      "      Specification of Use: Joint Replacement     0.0000    0.0000    0.0000        44\n",
      "                              Surgical Method     0.0000    0.0000    0.0000        40\n",
      "\n",
      "                                    micro avg     0.5775    0.2797    0.3769      1505\n",
      "                                    macro avg     0.0788    0.1364    0.0995      1505\n",
      "                                 weighted avg     0.1640    0.2797    0.2060      1505\n",
      "                                  samples avg     0.5775    0.3138    0.3838      1505\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    Anatomical Target       0.67      1.00      0.81       164\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "                  precision    recall  f1-score   support\n",
    "\n",
    "                        Analysis and Modeling       0.35      1.00      0.51        84\n",
    "           Analysis and Modeling: 3D Modeling       0.31      0.97      0.47        71\n",
    "                            Anatomical Target       0.67      1.00      0.81       164\n",
    "           Anatomical Target: Lower Extremity       0.47      1.00      0.63       113\n",
    "     Anatomical Target: Lower Extremity - Hip       0.16      1.00      0.28        40\n",
    "    Anatomical Target: Lower Extremity - Knee       0.34      1.00      0.50        82\n",
    "                     Anatomical Target: Torso       0.00      0.00      0.00        35\n",
    "             Anatomical Target: Torso - Spine       0.00      0.00      0.00        21\n",
    "           Anatomical Target: Upper Extremity       0.13      0.97      0.22        31\n",
    "Anatomical Target: Upper Extremity - Shoulder       0.00      0.00      0.00        23\n",
    "                                      Imaging       0.55      1.00      0.71       133\n",
    "                                  Imaging: CT       0.00      0.00      0.00        59\n",
    "                                 Imaging: MRI       0.00      0.00      0.00        59\n",
    "                          Imaging: Ultrasound       0.00      0.00      0.00        32\n",
    "                                Manufacturing       0.34      1.00      0.51        83\n",
    "        Manufacturing: Additive Manufacturing       0.00      0.00      0.00        38\n",
    "           Personalized Product: Guide or Jig       0.49      1.00      0.66       120\n",
    "                Personalized Product: Implant       0.51      1.00      0.68       124\n",
    "                         Specification of Use       0.33      1.00      0.49        79\n",
    "                Specification of Use: Disease       0.00      0.00      0.00        30\n",
    "      Specification of Use: Joint Replacement       0.21      0.91      0.34        44\n",
    "                              Surgical Method       0.00      0.00      0.00        40\n",
    "\n",
    "                                    micro avg       0.38      0.77      0.51      1505\n",
    "                                    macro avg       0.22      0.58      0.31      1505\n",
    "                                 weighted avg       0.34      0.77      0.46      1505\n",
    "                                  samples avg       0.38      0.80      0.49      1505"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stack(listOfDicts):\n",
    "#     initDict = listOfDicts[0]\n",
    "#     finalDict = {}\n",
    "#     for key in initDict.keys():\n",
    "#         tensors = tuple(d[key] for d in listOfDicts)\n",
    "#         finalDict[key] = torch.stack(tensors)\n",
    "#     return finalDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstracts = stack(list(tokenize(tokenizer, x, max_len=MAX_LEN_ABSTRACT) for x in testing_set.abstract))\n",
    "\n",
    "# claims = stack(list(tokenize(tokenizer, x, max_len=MAX_LEN_CLAIMS) for x in testing_set.claims))\n",
    "\n",
    "# predictions = model.forward(abstract=abstracts, claims=claims)\n",
    "\n",
    "# binarized = predictions.detach().numpy() > 0.5\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "# testing_labels = testing_set[subset]\n",
    "# print(classification_report(testing_labels, binarized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
