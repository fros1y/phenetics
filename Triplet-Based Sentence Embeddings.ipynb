{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/anaconda3/envs/phenetics/lib/python3.8/site-packages/tqdm/std.py:670: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, SentencesDataset, InputExample, LoggingHandler, losses, models, util\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import csv\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"/var/patentmark/transformer-training/patent-electra-v4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 16\n",
    "output_path = \"output/training-triplets-\"+model_name+\"-\"+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_model = models.Transformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                               pooling_mode_mean_tokens=True,\n",
    "                               pooling_mode_cls_token=False,\n",
    "                               pooling_mode_max_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-21 07:27:27 - Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-21 07:29:25 - Read Triplet train dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4c401fa72a4f598ba2fba454e701ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3701622.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def build_example(row):\n",
    "    return InputExample(texts=[row['label'], row['positive'], row['negative']], label=0)\n",
    "\n",
    "logging.info(\"Read Triplet train dataset\")\n",
    "train_examples_df = pd.read_parquet(\"training_triplets.parquet\")\n",
    "train_examples = train_examples_df.progress_apply(build_example, axis=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SentencesDataset(train_examples, model=model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.TripletLoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-21 07:30:35 - Read Triplet dev dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511c9a4545f541ce84d2123dd5b03657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Read Triplet dev dataset\")\n",
    "dev_examples_df = pd.read_parquet(\"testing_triplets.parquet\")\n",
    "dev_examples = train_examples_df.sample(10000).progress_apply(build_example, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = TripletEvaluator.from_input_examples(dev_examples, name='dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_steps = int(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d883c92d43504b2986e6e45acd77e5a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f01a396ddf4471399aa210d1151d45e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=231352.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-21 07:38:56 - TripletEvaluator: Evaluating the model on dev dataset in epoch 0 after 1000 steps:\n",
      "2020-11-21 07:40:45 - Accuracy Cosine Distance:   \t51.43\n",
      "2020-11-21 07:40:45 - Accuracy Manhatten Distance:\t51.12\n",
      "2020-11-21 07:40:45 - Accuracy Euclidean Distance:\t50.70\n",
      "\n",
      "2020-11-21 07:40:45 - Save model to output/training-triplets-/var/patentmark/transformer-training/patent-electra-v4-2020-11-21_07-27-24\n",
      "2020-11-21 07:49:05 - TripletEvaluator: Evaluating the model on dev dataset in epoch 0 after 2000 steps:\n",
      "2020-11-21 07:50:57 - Accuracy Cosine Distance:   \t55.11\n",
      "2020-11-21 07:50:57 - Accuracy Manhatten Distance:\t55.74\n",
      "2020-11-21 07:50:57 - Accuracy Euclidean Distance:\t54.32\n",
      "\n",
      "2020-11-21 07:50:57 - Save model to output/training-triplets-/var/patentmark/transformer-training/patent-electra-v4-2020-11-21_07-27-24\n",
      "2020-11-21 07:59:20 - TripletEvaluator: Evaluating the model on dev dataset in epoch 0 after 3000 steps:\n",
      "2020-11-21 08:01:11 - Accuracy Cosine Distance:   \t62.97\n",
      "2020-11-21 08:01:11 - Accuracy Manhatten Distance:\t63.38\n",
      "2020-11-21 08:01:11 - Accuracy Euclidean Distance:\t63.14\n",
      "\n",
      "2020-11-21 08:01:11 - Save model to output/training-triplets-/var/patentmark/transformer-training/patent-electra-v4-2020-11-21_07-27-24\n",
      "2020-11-21 08:09:33 - TripletEvaluator: Evaluating the model on dev dataset in epoch 0 after 4000 steps:\n",
      "2020-11-21 08:11:25 - Accuracy Cosine Distance:   \t69.62\n",
      "2020-11-21 08:11:25 - Accuracy Manhatten Distance:\t70.08\n",
      "2020-11-21 08:11:25 - Accuracy Euclidean Distance:\t69.85\n",
      "\n",
      "2020-11-21 08:11:25 - Save model to output/training-triplets-/var/patentmark/transformer-training/patent-electra-v4-2020-11-21_07-27-24\n",
      "2020-11-21 08:19:45 - TripletEvaluator: Evaluating the model on dev dataset in epoch 0 after 5000 steps:\n",
      "2020-11-21 08:21:36 - Accuracy Cosine Distance:   \t73.72\n",
      "2020-11-21 08:21:36 - Accuracy Manhatten Distance:\t73.89\n",
      "2020-11-21 08:21:36 - Accuracy Euclidean Distance:\t73.97\n",
      "\n",
      "2020-11-21 08:21:36 - Save model to output/training-triplets-/var/patentmark/transformer-training/patent-electra-v4-2020-11-21_07-27-24\n",
      "2020-11-21 08:29:53 - TripletEvaluator: Evaluating the model on dev dataset in epoch 0 after 6000 steps:\n",
      "2020-11-21 08:31:42 - Accuracy Cosine Distance:   \t76.09\n",
      "2020-11-21 08:31:42 - Accuracy Manhatten Distance:\t76.18\n",
      "2020-11-21 08:31:42 - Accuracy Euclidean Distance:\t76.55\n",
      "\n",
      "2020-11-21 08:31:42 - Save model to output/training-triplets-/var/patentmark/transformer-training/patent-electra-v4-2020-11-21_07-27-24\n",
      "2020-11-21 08:39:59 - TripletEvaluator: Evaluating the model on dev dataset in epoch 0 after 7000 steps:\n",
      "2020-11-21 08:41:48 - Accuracy Cosine Distance:   \t77.10\n",
      "2020-11-21 08:41:48 - Accuracy Manhatten Distance:\t77.40\n",
      "2020-11-21 08:41:48 - Accuracy Euclidean Distance:\t78.16\n",
      "\n",
      "2020-11-21 08:41:48 - Save model to output/training-triplets-/var/patentmark/transformer-training/patent-electra-v4-2020-11-21_07-27-24\n",
      "2020-11-21 08:50:05 - TripletEvaluator: Evaluating the model on dev dataset in epoch 0 after 8000 steps:\n",
      "2020-11-21 08:51:54 - Accuracy Cosine Distance:   \t78.47\n",
      "2020-11-21 08:51:54 - Accuracy Manhatten Distance:\t78.68\n",
      "2020-11-21 08:51:54 - Accuracy Euclidean Distance:\t79.38\n",
      "\n",
      "2020-11-21 08:51:54 - Save model to output/training-triplets-/var/patentmark/transformer-training/patent-electra-v4-2020-11-21_07-27-24\n",
      "2020-11-21 09:00:09 - TripletEvaluator: Evaluating the model on dev dataset in epoch 0 after 9000 steps:\n",
      "2020-11-21 09:01:58 - Accuracy Cosine Distance:   \t78.70\n",
      "2020-11-21 09:01:58 - Accuracy Manhatten Distance:\t79.28\n",
      "2020-11-21 09:01:58 - Accuracy Euclidean Distance:\t78.95\n",
      "\n",
      "2020-11-21 09:10:11 - TripletEvaluator: Evaluating the model on dev dataset in epoch 0 after 10000 steps:\n",
      "2020-11-21 09:12:00 - Accuracy Cosine Distance:   \t79.08\n",
      "2020-11-21 09:12:00 - Accuracy Manhatten Distance:\t79.27\n",
      "2020-11-21 09:12:00 - Accuracy Euclidean Distance:\t80.35\n",
      "\n",
      "2020-11-21 09:12:00 - Save model to output/training-triplets-/var/patentmark/transformer-training/patent-electra-v4-2020-11-21_07-27-24\n",
      "2020-11-21 09:20:20 - TripletEvaluator: Evaluating the model on dev dataset in epoch 0 after 11000 steps:\n",
      "2020-11-21 09:22:09 - Accuracy Cosine Distance:   \t80.15\n",
      "2020-11-21 09:22:09 - Accuracy Manhatten Distance:\t80.42\n",
      "2020-11-21 09:22:09 - Accuracy Euclidean Distance:\t81.42\n",
      "\n",
      "2020-11-21 09:22:09 - Save model to output/training-triplets-/var/patentmark/transformer-training/patent-electra-v4-2020-11-21_07-27-24\n",
      "2020-11-21 09:30:27 - TripletEvaluator: Evaluating the model on dev dataset in epoch 0 after 12000 steps:\n",
      "2020-11-21 09:32:17 - Accuracy Cosine Distance:   \t82.00\n",
      "2020-11-21 09:32:17 - Accuracy Manhatten Distance:\t81.81\n",
      "2020-11-21 09:32:17 - Accuracy Euclidean Distance:\t82.88\n",
      "\n",
      "2020-11-21 09:32:17 - Save model to output/training-triplets-/var/patentmark/transformer-training/patent-electra-v4-2020-11-21_07-27-24\n",
      "2020-11-21 09:40:33 - TripletEvaluator: Evaluating the model on dev dataset in epoch 0 after 13000 steps:\n",
      "2020-11-21 09:42:23 - Accuracy Cosine Distance:   \t82.34\n",
      "2020-11-21 09:42:23 - Accuracy Manhatten Distance:\t82.33\n",
      "2020-11-21 09:42:23 - Accuracy Euclidean Distance:\t83.68\n",
      "\n",
      "2020-11-21 09:42:23 - Save model to output/training-triplets-/var/patentmark/transformer-training/patent-electra-v4-2020-11-21_07-27-24\n",
      "2020-11-21 09:50:40 - TripletEvaluator: Evaluating the model on dev dataset in epoch 0 after 14000 steps:\n",
      "2020-11-21 09:52:30 - Accuracy Cosine Distance:   \t81.96\n",
      "2020-11-21 09:52:30 - Accuracy Manhatten Distance:\t80.58\n",
      "2020-11-21 09:52:30 - Accuracy Euclidean Distance:\t83.35\n",
      "\n",
      "2020-11-21 10:00:46 - TripletEvaluator: Evaluating the model on dev dataset in epoch 0 after 15000 steps:\n",
      "2020-11-21 10:02:36 - Accuracy Cosine Distance:   \t82.34\n",
      "2020-11-21 10:02:36 - Accuracy Manhatten Distance:\t82.19\n",
      "2020-11-21 10:02:36 - Accuracy Euclidean Distance:\t84.11\n",
      "\n",
      "2020-11-21 10:02:37 - Save model to output/training-triplets-/var/patentmark/transformer-training/patent-electra-v4-2020-11-21_07-27-24\n",
      "2020-11-21 10:10:55 - TripletEvaluator: Evaluating the model on dev dataset in epoch 0 after 16000 steps:\n",
      "2020-11-21 10:12:44 - Accuracy Cosine Distance:   \t84.46\n",
      "2020-11-21 10:12:44 - Accuracy Manhatten Distance:\t83.35\n",
      "2020-11-21 10:12:44 - Accuracy Euclidean Distance:\t85.12\n",
      "\n",
      "2020-11-21 10:12:44 - Save model to output/training-triplets-/var/patentmark/transformer-training/patent-electra-v4-2020-11-21_07-27-24\n",
      "2020-11-21 10:21:00 - TripletEvaluator: Evaluating the model on dev dataset in epoch 0 after 17000 steps:\n",
      "2020-11-21 10:22:50 - Accuracy Cosine Distance:   \t83.96\n",
      "2020-11-21 10:22:50 - Accuracy Manhatten Distance:\t82.46\n",
      "2020-11-21 10:22:50 - Accuracy Euclidean Distance:\t85.36\n",
      "\n",
      "2020-11-21 10:22:50 - Save model to output/training-triplets-/var/patentmark/transformer-training/patent-electra-v4-2020-11-21_07-27-24\n",
      "2020-11-21 10:31:07 - TripletEvaluator: Evaluating the model on dev dataset in epoch 0 after 18000 steps:\n",
      "2020-11-21 10:32:55 - Accuracy Cosine Distance:   \t85.37\n",
      "2020-11-21 10:32:55 - Accuracy Manhatten Distance:\t83.94\n",
      "2020-11-21 10:32:55 - Accuracy Euclidean Distance:\t86.82\n",
      "\n",
      "2020-11-21 10:32:55 - Save model to output/training-triplets-/var/patentmark/transformer-training/patent-electra-v4-2020-11-21_07-27-24\n",
      "2020-11-21 10:41:12 - TripletEvaluator: Evaluating the model on dev dataset in epoch 0 after 19000 steps:\n",
      "2020-11-21 10:43:03 - Accuracy Cosine Distance:   \t86.20\n",
      "2020-11-21 10:43:03 - Accuracy Manhatten Distance:\t84.67\n",
      "2020-11-21 10:43:03 - Accuracy Euclidean Distance:\t87.64\n",
      "\n",
      "2020-11-21 10:43:03 - Save model to output/training-triplets-/var/patentmark/transformer-training/patent-electra-v4-2020-11-21_07-27-24\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d9e0c253f53e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.fit(train_objectives=[(train_dataloader, train_loss)],\n\u001b[0m\u001b[1;32m      3\u001b[0m           \u001b[0mevaluator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mevaluation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, output_path_ignore_not_empty)\u001b[0m\n\u001b[1;32m    583\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                         \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m                         \u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=output_path)\n",
    "\n",
    "# ##############################################################################\n",
    "# #\n",
    "# # Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "# #\n",
    "# ##############################################################################\n",
    "\n",
    "# logging.info(\"Read test examples\")\n",
    "# test_examples = []\n",
    "# with open(os.path.join(dataset_path, 'test.csv'), encoding=\"utf-8\") as fIn:\n",
    "#     reader = csv.DictReader(fIn, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "#     for row in reader:\n",
    "#         test_examples.append(InputExample(texts=[row['Sentence1'], row['Sentence2'], row['Sentence3']]))\n",
    "\n",
    "\n",
    "# model = SentenceTransformer(output_path)\n",
    "# test_evaluator = TripletEvaluator.from_input_examples(test_examples, name='test')\n",
    "# test_evaluator(model, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
