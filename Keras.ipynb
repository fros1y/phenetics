{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import *\n",
    "from sklearn.feature_extraction.text import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import scipy.sparse as sps\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_json(\"training_set.json.gz\", lines=True, orient=\"records\")\n",
    "testing_set = pd.read_json(\"testing_set.json.gz\", lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_vectorizer = TfidfVectorizer(min_df=5)\n",
    "\n",
    "# abstract_vectors = text_vectorizer.fit_transform(training_set.abstract)\n",
    "# test_abstract_vectors = text_vectorizer.transform(testing_set.abstract)\n",
    "\n",
    "# text_vectorizer = TfidfVectorizer(min_df=5)\n",
    "\n",
    "# claim_vectors = text_vectorizer.fit_transform(training_set.claims)\n",
    "# test_claim_vectors = text_vectorizer.transform(testing_set.claims)\n",
    "\n",
    "# text_vectorizer = TfidfVectorizer(min_df=2, max_df=0.5)\n",
    "\n",
    "# desc_vectors = text_vectorizer.fit_transform(training_set.description)\n",
    "# test_desc_vectors = text_vectorizer.transform(testing_set.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AnalysisAndModeling',\n",
       " 'Manufacturing',\n",
       " 'SpecificationofUse',\n",
       " 'SurgicalMethod',\n",
       " 'Imaging',\n",
       " 'AnatomicalTarget']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = list(set(tier1) & set(all_tiers_100))\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = training_set[subset].values.astype(int)\n",
    "test_labels = testing_set[subset].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(972, 6)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# # def tokenize(sentences, tokenizer):\n",
    "# #     input_ids, input_masks, input_segments = [],[],[]\n",
    "# #     for sentence in tqdm(sentences):\n",
    "# #         inputs = tokenizer.encode_plus(sentence,\n",
    "# #                                        truncation=True,\n",
    "# #                                        add_special_tokens=True, \n",
    "# #                                        max_length=256,\n",
    "# #                                        padding=True,\n",
    "# #                                        return_tensors='tf',\n",
    "# #                                        #pad_to_max_length=True,\n",
    "# #                                        return_attention_mask=False, \n",
    "# #                                        return_token_type_ids=False)\n",
    "# #         input_ids.append(inputs['input_ids'])\n",
    "# #         input_masks.append(inputs['attention_mask'])\n",
    "# #         input_segments.append(inputs['token_type_ids'])        \n",
    "        \n",
    "#     return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32'), np.asarray(input_segments, dtype='int32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['classifier.bias', 'classifier.weight', 'bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"/var/patentmark/patentBERT/\")\n",
    "transformer = TFAutoModel.from_pretrained(\"/var/patentmark/patentBERT/\", from_pt=True)\n",
    "config = AutoConfig.from_pretrained(\"/var/patentmark/patentBERT/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_input_ids = tokenizer(text=training_set.claims.to_list(),\n",
    "                            truncation=True,\n",
    "                           add_special_tokens=True, \n",
    "                           max_length=max_length,\n",
    "                           padding=True,\n",
    "                           return_tensors='tf',\n",
    "                           #pad_to_max_length=True,\n",
    "                           return_attention_mask=False, \n",
    "                           return_token_type_ids=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_claim_input_ids = tokenizer(text=testing_set.claims.to_list(),\n",
    "                            truncation=True,\n",
    "                           add_special_tokens=True, \n",
    "                           max_length=max_length,\n",
    "                           padding=True,\n",
    "                           return_tensors='tf',\n",
    "                           #pad_to_max_length=True,\n",
    "                           return_attention_mask=False, \n",
    "                           return_token_type_ids=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# claim_input_ids, claim_masks, _ = tokenize(training_set.claims, tokenizer)\n",
    "# test_claim_input_ids, test_claim_masks, _ = tokenize(testing_set.claims, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    #claim_input = layers.Input(shape=(claim_vectors.shape[1]))\n",
    "    #description_input = layers.Input(shape=(desc_vectors.shape[1]))\n",
    "    \n",
    "    #claim_ids_in = layers.Input(shape=(max_length,), dtype='int32')\n",
    "    #claim_masks_in = layers.Input(shape=(claim_masks.shape[1]), dtype='int32')\n",
    "    #claim_embedding_layer = transformer(claim_ids_in)[1]\n",
    "    #, attention_mask=claim_masks_in)[0]\n",
    "    #claim_embedding_layer = layers.GlobalAveragePooling1D()(claim_embedding_layer)\n",
    "    \n",
    "    #concat_layer = layers.Concatenate()([claim_input])\n",
    "    #dropout = layers.Dropout(config.hidden_dropout_prob)(claim_embedding_layer, training=False)\n",
    "    \n",
    "    abstract_input = layers.Input(shape=(abstract_vectors.shape[1]), name=\"abstract_vectors\")\n",
    "    claim_input = layers.Input(shape=(claim_vectors.shape[1]), name=\"claim_vectors\")\n",
    "    \n",
    "    concat = layers.Concatenate()((abstract_input, claim_input))\n",
    "    dropout0 = layers.Dropout(0.7)(concat)\n",
    "    dense0 = layers.Dense(64, activation='elu')(dropout0)\n",
    "    dropout1 = layers.Dropout(0.7)(dense0)\n",
    "    output = layers.Dense(units=len(subset), activation='sigmoid')(dropout1)\n",
    "    \n",
    "                          #kernel_initializer=keras.initializers.TruncatedNormal(stddev=config.initializer_range))(dense0)\n",
    "    \n",
    "    #, activation='sigmoid')(dropout)\n",
    "    \n",
    "    #optimizer = tfa.optimizers.AdamW(weight_decay=0.01, learning_rate=1e-05, epsilon=1e-08)\n",
    "    loss = keras.losses.BinaryCrossentropy()\n",
    "    #metric = keras.metrics.CategoricalAccuracy('accuracy')\n",
    "    metric = tfa.metrics.HammingLoss(mode='multilabel', threshold=0.5)\n",
    "    #metric = 'categorical_accuracy'\n",
    "    \n",
    "    net = models.Model([claim_input, abstract_input], output)\n",
    "    \n",
    "    net.compile(loss=loss, metrics=[metric], optimizer=\"adam\")\n",
    "#     for layer in net.layers[:3]:\n",
    "#         layer.trainable = False\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "abstract_vectors (InputLayer)   [(None, 1275)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "claim_vectors (InputLayer)      [(None, 2845)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 4120)         0           abstract_vectors[0][0]           \n",
      "                                                                 claim_vectors[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 4120)         0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 64)           263744      dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)            (None, 64)           0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 6)            390         dropout_89[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 264,134\n",
      "Trainable params: 264,134\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6978 - hamming_loss: 0.5159 - val_loss: 0.6896 - val_hamming_loss: 0.4487 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6906 - hamming_loss: 0.4683 - val_loss: 0.6833 - val_hamming_loss: 0.3940 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6842 - hamming_loss: 0.4397 - val_loss: 0.6774 - val_hamming_loss: 0.3538 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6794 - hamming_loss: 0.4215 - val_loss: 0.6718 - val_hamming_loss: 0.3521 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6745 - hamming_loss: 0.4005 - val_loss: 0.6666 - val_hamming_loss: 0.3487 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6695 - hamming_loss: 0.3837 - val_loss: 0.6617 - val_hamming_loss: 0.3462 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6632 - hamming_loss: 0.3812 - val_loss: 0.6571 - val_hamming_loss: 0.3427 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6597 - hamming_loss: 0.3747 - val_loss: 0.6529 - val_hamming_loss: 0.3436 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6545 - hamming_loss: 0.3662 - val_loss: 0.6489 - val_hamming_loss: 0.3419 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6510 - hamming_loss: 0.3651 - val_loss: 0.6451 - val_hamming_loss: 0.3419 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 1s - loss: 0.6470 - hamming_loss: 0.3539 - val_loss: 0.6417 - val_hamming_loss: 0.3427 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6442 - hamming_loss: 0.3550 - val_loss: 0.6385 - val_hamming_loss: 0.3436 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6411 - hamming_loss: 0.3556 - val_loss: 0.6355 - val_hamming_loss: 0.3419 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6389 - hamming_loss: 0.3501 - val_loss: 0.6328 - val_hamming_loss: 0.3368 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6360 - hamming_loss: 0.3533 - val_loss: 0.6303 - val_hamming_loss: 0.3368 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6350 - hamming_loss: 0.3509 - val_loss: 0.6280 - val_hamming_loss: 0.3402 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6318 - hamming_loss: 0.3490 - val_loss: 0.6259 - val_hamming_loss: 0.3376 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6289 - hamming_loss: 0.3451 - val_loss: 0.6241 - val_hamming_loss: 0.3333 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6265 - hamming_loss: 0.3494 - val_loss: 0.6223 - val_hamming_loss: 0.3316 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6294 - hamming_loss: 0.3488 - val_loss: 0.6208 - val_hamming_loss: 0.3291 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6223 - hamming_loss: 0.3419 - val_loss: 0.6194 - val_hamming_loss: 0.3248 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6228 - hamming_loss: 0.3421 - val_loss: 0.6181 - val_hamming_loss: 0.3248 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6220 - hamming_loss: 0.3400 - val_loss: 0.6170 - val_hamming_loss: 0.3256 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6234 - hamming_loss: 0.3477 - val_loss: 0.6160 - val_hamming_loss: 0.3248 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6157 - hamming_loss: 0.3426 - val_loss: 0.6151 - val_hamming_loss: 0.3256 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 1s - loss: 0.6174 - hamming_loss: 0.3451 - val_loss: 0.6143 - val_hamming_loss: 0.3231 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6154 - hamming_loss: 0.3357 - val_loss: 0.6135 - val_hamming_loss: 0.3265 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6130 - hamming_loss: 0.3301 - val_loss: 0.6129 - val_hamming_loss: 0.3291 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6135 - hamming_loss: 0.3389 - val_loss: 0.6122 - val_hamming_loss: 0.3265 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6121 - hamming_loss: 0.3355 - val_loss: 0.6117 - val_hamming_loss: 0.3282 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6107 - hamming_loss: 0.3344 - val_loss: 0.6112 - val_hamming_loss: 0.3282 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6129 - hamming_loss: 0.3346 - val_loss: 0.6107 - val_hamming_loss: 0.3274 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6120 - hamming_loss: 0.3348 - val_loss: 0.6103 - val_hamming_loss: 0.3256 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6062 - hamming_loss: 0.3284 - val_loss: 0.6100 - val_hamming_loss: 0.3265 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6042 - hamming_loss: 0.3295 - val_loss: 0.6096 - val_hamming_loss: 0.3256 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6062 - hamming_loss: 0.3308 - val_loss: 0.6093 - val_hamming_loss: 0.3256 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6042 - hamming_loss: 0.3245 - val_loss: 0.6093 - val_hamming_loss: 0.3256 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6035 - hamming_loss: 0.3267 - val_loss: 0.6093 - val_hamming_loss: 0.3256 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6016 - hamming_loss: 0.3258 - val_loss: 0.6092 - val_hamming_loss: 0.3256 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6067 - hamming_loss: 0.3265 - val_loss: 0.6092 - val_hamming_loss: 0.3256 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6033 - hamming_loss: 0.3215 - val_loss: 0.6092 - val_hamming_loss: 0.3256 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 1s - loss: 0.6056 - hamming_loss: 0.3275 - val_loss: 0.6091 - val_hamming_loss: 0.3256 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6046 - hamming_loss: 0.3271 - val_loss: 0.6091 - val_hamming_loss: 0.3256 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6029 - hamming_loss: 0.3295 - val_loss: 0.6091 - val_hamming_loss: 0.3256 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6039 - hamming_loss: 0.3256 - val_loss: 0.6091 - val_hamming_loss: 0.3256 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6046 - hamming_loss: 0.3301 - val_loss: 0.6091 - val_hamming_loss: 0.3256 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6025 - hamming_loss: 0.3256 - val_loss: 0.6091 - val_hamming_loss: 0.3256 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.6034 - hamming_loss: 0.3177 - val_loss: 0.6091 - val_hamming_loss: 0.3256 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.5994 - hamming_loss: 0.3181 - val_loss: 0.6090 - val_hamming_loss: 0.3256 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6010 - hamming_loss: 0.3269 - val_loss: 0.6090 - val_hamming_loss: 0.3256 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6006 - hamming_loss: 0.3235 - val_loss: 0.6090 - val_hamming_loss: 0.3256 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6020 - hamming_loss: 0.3211 - val_loss: 0.6090 - val_hamming_loss: 0.3256 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6031 - hamming_loss: 0.3192 - val_loss: 0.6090 - val_hamming_loss: 0.3256 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6001 - hamming_loss: 0.3215 - val_loss: 0.6090 - val_hamming_loss: 0.3256 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6008 - hamming_loss: 0.3155 - val_loss: 0.6090 - val_hamming_loss: 0.3256 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "INFO:tensorflow:Assets written to: keras-model/assets\n",
      "1/1 - 0s - loss: 0.6023 - hamming_loss: 0.3218 - val_loss: 0.6090 - val_hamming_loss: 0.3256 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5b64791f40>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import * \n",
    "\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "callbacks = [\n",
    "        ReduceLROnPlateau(monitor='val_hamming_loss'),\n",
    "        EarlyStopping(patience=30, monitor='val_hamming_loss'),\n",
    "        ModelCheckpoint(filepath=\"keras-model\", save_best_only=True),\n",
    "        tensorboard_callback\n",
    "    ]\n",
    "\n",
    "model.fit(x={\"claim_vectors\": claim_vectors.todense(),\n",
    "             \"abstract_vectors\": abstract_vectors.todense()}, \n",
    "          y=labels,\n",
    "          verbose=2, \n",
    "          epochs=100, \n",
    "          validation_split=0.2, \n",
    "          batch_size=1024,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict({\"abstract_vectors\": abstract_vectors.todense(),\n",
    "                       \"claim_vectors\": claim_vectors.todense()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[preds>=0.5] = 1\n",
    "preds[preds<0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "AnalysisAndModeling       0.00      0.00      0.00       342\n",
      "      Manufacturing       1.00      0.04      0.08       387\n",
      " SpecificationofUse       0.00      0.00      0.00       347\n",
      "     SurgicalMethod       0.00      0.00      0.00       161\n",
      "            Imaging       0.64      0.95      0.77       517\n",
      "   AnatomicalTarget       0.63      1.00      0.77       606\n",
      "\n",
      "          micro avg       0.64      0.47      0.54      2360\n",
      "          macro avg       0.38      0.33      0.27      2360\n",
      "       weighted avg       0.47      0.47      0.38      2360\n",
      "        samples avg       0.66      0.49      0.53      2360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels, preds, target_names=subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds =model.predict({\"claim_vectors\": test_claim_vectors.todense(),\n",
    "                           \"abstract_vectors\": test_abstract_vectors.todense()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds[test_preds>=0.5] = 1\n",
    "test_preds[test_preds<0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "AnalysisAndModeling       0.00      0.00      0.00        84\n",
      "      Manufacturing       0.00      0.00      0.00        83\n",
      " SpecificationofUse       0.00      0.00      0.00        79\n",
      "     SurgicalMethod       0.00      0.00      0.00        40\n",
      "            Imaging       0.59      0.92      0.72       133\n",
      "   AnatomicalTarget       0.68      0.99      0.80       164\n",
      "\n",
      "          micro avg       0.63      0.49      0.55       583\n",
      "          macro avg       0.21      0.32      0.25       583\n",
      "       weighted avg       0.32      0.49      0.39       583\n",
      "        samples avg       0.65      0.52      0.55       583\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, test_preds, target_names=subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
