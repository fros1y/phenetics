{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from catalyst import dl\n",
    "from catalyst import dl, utils\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import logging\n",
    "from util import *\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_json(\"training_set.json.gz\", lines=True, orient=\"records\")\n",
    "testing_set = pd.read_json(\"testing_set.json.gz\", lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = list(set(all_tiers_100)-set([\"PersonalizedProduct\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['labels']=training_set[subset].astype(int).values.tolist()\n",
    "testing_set['labels']=testing_set[subset].astype(int).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc_embeddings = np.fromfile(\"/home/martin/patentmark/cpc.emb.verse.32d.bin\", dtype=np.float32).reshape((-1,32))\n",
    "cpc_labelizer = joblib.load('./node2id.joblib')\n",
    "cpc_lookup = {c: n for n, c in enumerate(cpc_labelizer.classes_)}\n",
    "\n",
    "@f.collecting\n",
    "def convert_cpc_codes(codes):\n",
    "    for code in codes:\n",
    "        if code in cpc_lookup:\n",
    "            yield cpc_lookup[code]\n",
    "    \n",
    "def embed_cpc_codes(codes):\n",
    "    embedding = np.zeros(32)\n",
    "    converted = convert_cpc_codes(codes)\n",
    "    \n",
    "    if not converted:\n",
    "        return embedding\n",
    "    \n",
    "    for code_id in converted:\n",
    "        embedding = embedding + cpc_embeddings[code_id]\n",
    "        \n",
    "    return embedding / len(converted)\n",
    "\n",
    "training_set['embedded_cpc'] = training_set.cpc_codes.apply(embed_cpc_codes)\n",
    "testing_set['embedded_cpc'] = testing_set.cpc_codes.apply(embed_cpc_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN_CLAIMS = 512\n",
    "MAX_LEN_ABSTRACT = 160\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 8\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 5e-5\n",
    "SEED = 17\n",
    "PRED_THRES = 0.4\n",
    "ACCUM_STEPS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = \"allenai/longformer-base-4096\"\n",
    "#model_name = \"albert-base-v2\"\n",
    "model_name = \"/home/martin/IdeaProjects/phenetics/bertForPatents/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['citing'] = training_set[['citations', 'cited_by']].apply(\n",
    "        lambda row: list(set(row['citations']+row['cited_by'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set['citing'] = testing_set[['citations', 'cited_by']].apply(\n",
    "        lambda row: list(set(row['citations']+row['cited_by'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['people'] = training_set[['assignees', 'inventors']].apply(lambda row: list(set(row['assignees']+row['inventors'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set['people'] = testing_set[['assignees', 'inventors']].apply(lambda row: list(set(row['assignees']+row['inventors'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format(t):\n",
    "    CORP_TYPES = set(\n",
    "        [\n",
    "            \"INC\",\n",
    "            \"LLC\" \"CORP\",\n",
    "            \"KK\",\n",
    "            \"SA\",\n",
    "            \"SRL\",\n",
    "            \"LTD\",\n",
    "            \"NL\",\n",
    "            \"PTY\",\n",
    "            \"AG\",\n",
    "            \"GMBH\",\n",
    "            \"KG\",\n",
    "            \"OG\",\n",
    "            \"LIMITED\",\n",
    "            \"SARL\",\n",
    "            \"BM\",\n",
    "            \"PLC\",\n",
    "            \"LP\",\n",
    "            \"IP\",\n",
    "            \"DBA\",\n",
    "            \"CORP\",\n",
    "            \"CO\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    tokenized = strip_non_alphanum(strip_punctuation(t)).upper().split(\" \")\n",
    "    cleaned = [t for t in tokenized if t not in CORP_TYPES]\n",
    "    return \"\".join(cleaned)\n",
    "\n",
    "\n",
    "people_coder = CountVectorizer(analyzer=lambda x: map(format, x), min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "citing_coder = CountVectorizer(analyzer=lambda x: x, min_df=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=<function <lambda> at 0x7f93b258e940>, min_df=4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citing_coder.fit(training_set.citing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=<function <lambda> at 0x7f93b258e310>, min_df=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_coder.fit(training_set.people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['people_vec'] = list(np.array(people_coder.transform(training_set.people).todense()))\n",
    "testing_set['people_vec'] = list(np.array(people_coder.transform(testing_set.people).todense()))\n",
    "training_set['citing_vec'] = list(np.array(citing_coder.transform(training_set.citing).todense()))\n",
    "testing_set['citing_vec'] = list(np.array(citing_coder.transform(testing_set.citing).todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        \n",
    "        self.claims = dataframe.claims\n",
    "        self.abstracts = dataframe.abstract\n",
    "        \n",
    "        self.targets = self.data.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def tokenize(self, text, max_len, prefix=\"\"):\n",
    "        text = str(text)\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            f\"input_ids\": torch.tensor(ids, dtype=torch.long),\n",
    "            f\"attention_mask\": torch.tensor(mask, dtype=torch.long),\n",
    "            f\"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
    "        }\n",
    "    \n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        abstract = self.tokenize(self.abstracts[index], max_len=MAX_LEN_ABSTRACT, prefix=\"abstract_\")\n",
    "        claims = self.tokenize(self.claims[index], MAX_LEN_CLAIMS, prefix=\"claims_\")\n",
    "        \n",
    "        #cpcs = torch.tensor(np.array(self.data.cpc_vec[index].values), dtype=torch.float)\n",
    "        people = torch.tensor(np.array(self.data.people_vec[index]), dtype=torch.float)\n",
    "        citing = torch.tensor(np.array(self.data.citing_vec[index]), dtype=torch.float)\n",
    "        embedded_cpc = torch.tensor(np.array(self.data.embedded_cpc[index]), dtype=torch.float)\n",
    "        return {\"abstract\": abstract, \n",
    "                \"claims\": claims, \n",
    "                \n",
    "                #'cpcs': cpcs,\n",
    "                 'people': people,\n",
    "                 'citing': citing,\n",
    "                 'embedded_cpc': embedded_cpc,\n",
    "                 'targets': torch.tensor(self.targets[index], dtype=torch.float)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = MultiLabelDataset(training_set, tokenizer)\n",
    "testing_dataset = MultiLabelDataset(testing_set, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_dataset, **train_params)\n",
    "testing_loader = DataLoader(testing_dataset, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\"train\": training_loader, \"valid\": testing_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModel.from_pretrained(model_name, gradient_checkpointing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Model2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.text_embedder = AutoModel.from_pretrained(model_name, gradient_checkpointing=True)\n",
    "        \n",
    "        for param in self.text_embedder.parameters():\n",
    "            param.requires_grad = False\n",
    "        #self.cpc_embedder = torch.nn.EmbeddingBag.from_pretrained(torch.from_numpy(cpc_embeddings))\n",
    "        \n",
    "        self.people_embedder = torch.nn.Linear(len(people_coder.vocabulary_), 16)\n",
    "        self.citing_embedder = torch.nn.Linear(len(citing_coder.vocabulary_), 16)\n",
    "        \n",
    "        total_embedding_size = self.text_embedder.pooler.dense.out_features*2+32+16*2\n",
    "        output_size = len(subset)\n",
    "        bottleneck = 768\n",
    "        \n",
    "        #self.batch_norm1 = nn.BatchNorm1d(total_embedding_size)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.Linear(total_embedding_size, bottleneck)\n",
    "        \n",
    "        #self.batch_norm2 = nn.BatchNorm1d(bottleneck)\n",
    "        #self.dropout2 = nn.Dropout(0.1)\n",
    "        #self.dense2 = nn.utils.weight_norm(nn.Linear(bottleneck, output_size))\n",
    "        self.classifier = nn.Linear(bottleneck, output_size)\n",
    "\n",
    "            \n",
    "    def forward(self, abstract, claims, embedded_cpc, people, citing):\n",
    "        \n",
    "        abstract_emb = self.text_embedder(input_ids=abstract[\"input_ids\"], attention_mask=abstract[\"attention_mask\"])\n",
    "        abstract_emb = abstract_emb[0][:, 0]\n",
    "        \n",
    "        claim_emb = self.text_embedder(input_ids=claims[\"input_ids\"], attention_mask=claims[\"attention_mask\"])\n",
    "        claim_emb = claim_emb[0][:, 0]\n",
    "        \n",
    "        people_emb = F.elu(self.people_embedder(people))\n",
    "        citing_emb = F.elu(self.citing_embedder(citing))\n",
    "    \n",
    "        x = torch.cat((abstract_emb, claim_emb, embedded_cpc, people_emb, citing_emb), 1)\n",
    "        #x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.elu(self.dense1(x))\n",
    "        \n",
    "        #x = self.batch_norm2(x)\n",
    "        #x = self.dropout2(x)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = Model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = utils.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "logdir=\"logdir/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d0e2f5c6b101956e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d0e2f5c6b101956e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logdir/fit/ --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catalyst.contrib as contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/100 * Epoch (train):   0% 0/122 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100 * Epoch (train): 100% 122/122 [01:40<00:00,  1.22it/s, loss=0.481, multi_label_accuracy=0.784]\n",
      "1/100 * Epoch (valid): 100% 31/31 [00:25<00:00,  1.23it/s, loss=0.434, multi_label_accuracy=0.803]\n",
      "[2020-12-02 19:41:19,451] \n",
      "1/100 * Epoch 1 (_base): lr=5.000e-05 | momentum=0.9000\n",
      "1/100 * Epoch 1 (train): loss=0.5654 | multi_label_accuracy=0.7225\n",
      "1/100 * Epoch 1 (valid): loss=0.5328 | multi_label_accuracy=0.7372\n",
      "2/100 * Epoch (train): 100% 122/122 [01:43<00:00,  1.18it/s, loss=0.616, multi_label_accuracy=0.682]\n",
      "2/100 * Epoch (valid): 100% 31/31 [00:24<00:00,  1.25it/s, loss=0.456, multi_label_accuracy=0.803]\n",
      "[2020-12-02 19:43:34,517] \n",
      "2/100 * Epoch 2 (_base): lr=5.000e-05 | momentum=0.9000\n",
      "2/100 * Epoch 2 (train): loss=0.5325 | multi_label_accuracy=0.7292\n",
      "2/100 * Epoch 2 (valid): loss=0.5287 | multi_label_accuracy=0.7299\n",
      "3/100 * Epoch (train): 100% 122/122 [01:42<00:00,  1.19it/s, loss=0.457, multi_label_accuracy=0.739]\n",
      "3/100 * Epoch (valid): 100% 31/31 [00:24<00:00,  1.25it/s, loss=0.448, multi_label_accuracy=0.803]\n",
      "[2020-12-02 19:45:54,011] \n",
      "3/100 * Epoch 3 (_base): lr=5.000e-05 | momentum=0.9000\n",
      "3/100 * Epoch 3 (train): loss=0.5252 | multi_label_accuracy=0.7318\n",
      "3/100 * Epoch 3 (valid): loss=0.5255 | multi_label_accuracy=0.7356\n",
      "4/100 * Epoch (train): 100% 122/122 [01:42<00:00,  1.19it/s, loss=0.466, multi_label_accuracy=0.750]\n",
      "4/100 * Epoch (valid): 100% 31/31 [00:25<00:00,  1.24it/s, loss=0.466, multi_label_accuracy=0.803]\n",
      "[2020-12-02 19:48:14,604] \n",
      "4/100 * Epoch 4 (_base): lr=5.000e-05 | momentum=0.9000\n",
      "4/100 * Epoch 4 (train): loss=0.5205 | multi_label_accuracy=0.7351\n",
      "4/100 * Epoch 4 (valid): loss=0.5260 | multi_label_accuracy=0.7319\n",
      "Early stop at 4 epoch\n",
      "Top best models:\n",
      "logdir/fit/20201202-193834/checkpoints/train.3.pth\t0.5255\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "#criterion = contrib.nn.criterion.LovaszLossMultiLabel()\n",
    "optimizer = torch.optim.AdamW(params =  model.parameters(), lr=LEARNING_RATE)\n",
    "#scheduler = contrib.nn.OneCycleLRWithWarmup(optimizer, num_steps=500, lr_range=(1e-4, 1e-8), init_lr=1e-9, warmup_fraction=0.2)\n",
    "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [2])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "#lrfinder = dl.LRFinder(final_lr=1)\n",
    "\n",
    "runner = dl.SupervisedRunner(input_key=(\"abstract\", \"claims\", \"embedded_cpc\", \"people\", \"citing\"))\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loaders=loaders,\n",
    "    logdir=logdir,\n",
    "    num_epochs=EPOCHS,\n",
    "    callbacks=[\n",
    "               dl.MultiLabelAccuracyCallback(threshold=PRED_THRES, activation=\"None\"),\n",
    "               dl.EarlyStoppingCallback(patience=3, metric=\"multi_label_accuracy\", minimize=False),\n",
    "               dl.TensorboardLogger(),\n",
    "               #dl.CheckpointCallback(),\n",
    "               dl.OptimizerCallback(accumulation_steps=ACCUM_STEPS),\n",
    "               dl.ValidationManagerCallback(),\n",
    "               ],\n",
    "               #dl.MetricManagerCallback(num_classes=len(subset), )],\n",
    "    \n",
    "    fp16=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.vstack(list(map(\n",
    "    lambda x: x[\"logits\"].cpu().numpy(), \n",
    "    runner.predict_loader(loader=loaders[\"valid\"], resume=f\"{logdir}/checkpoints/best.pth\" )\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_predictions = torch.sigmoid(torch.from_numpy(predictions)) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "print(classification_report(testing_set[subset].astype(int), binary_predictions, target_names=subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "     SpecificationofUse_JointReplacement       0.21      0.32      0.25        44\n",
    "                                 Imaging       0.55      1.00      0.71       133\n",
    "                          SurgicalMethod       0.00      0.00      0.00        40\n",
    "     Manufacturing_AdditiveManufacturing       0.00      0.00      0.00        38\n",
    "                      Imaging_Ultrasound       0.00      0.00      0.00        32\n",
    "                             Imaging_MRI       0.34      0.20      0.26        59\n",
    "AnatomicalTarget_UpperExtremity_Shoulder       0.00      0.00      0.00        23\n",
    "              SpecificationofUse_Disease       0.00      0.00      0.00        30\n",
    "             PersonalizedProduct_Implant       0.51      1.00      0.68       124\n",
    "                           Manufacturing       0.34      0.90      0.49        83\n",
    "         AnatomicalTarget_UpperExtremity       0.00      0.00      0.00        31\n",
    "                     AnalysisAndModeling       0.36      0.96      0.52        84\n",
    "         AnatomicalTarget_LowerExtremity       0.47      1.00      0.63       113\n",
    "                      SpecificationofUse       0.34      0.99      0.50        79\n",
    "                        AnatomicalTarget       0.67      1.00      0.81       164\n",
    "           PersonalizedProduct_Guide/Jig       0.49      1.00      0.66       120\n",
    "            AnatomicalTarget_Torso_Spine       0.00      0.00      0.00        21\n",
    "                              Imaging_CT       0.29      0.31      0.30        59\n",
    "          AnalysisAndModeling_3DModeling       0.30      0.93      0.46        71\n",
    "    AnatomicalTarget_LowerExtremity_Knee       0.34      0.78      0.48        82\n",
    "                  AnatomicalTarget_Torso       0.00      0.00      0.00        35\n",
    "     AnatomicalTarget_LowerExtremity_Hip       0.00      0.00      0.00        40\n",
    "\n",
    "                               micro avg       0.43      0.71      0.54      1505\n",
    "                               macro avg       0.24      0.47      0.31      1505\n",
    "                            weighted avg       0.36      0.71      0.47      1505\n",
    "                             samples avg       0.43      0.74      0.52      1505"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longformer base (claims + abstract)\n",
    "                                            precision    recall  f1-score   support\n",
    "\n",
    "                     AnalysisAndModeling       0.35      1.00      0.51        84\n",
    "                        AnatomicalTarget       0.67      1.00      0.81       164\n",
    "            AnatomicalTarget_Torso_Spine       0.00      0.00      0.00        21\n",
    "     AnatomicalTarget_LowerExtremity_Hip       0.00      0.00      0.00        40\n",
    "                             Imaging_MRI       0.00      0.00      0.00        59\n",
    "                                 Imaging       0.55      1.00      0.71       133\n",
    "                           Manufacturing       0.34      0.99      0.50        83\n",
    "             PersonalizedProduct_Implant       0.51      1.00      0.68       124\n",
    "              SpecificationofUse_Disease       0.00      0.00      0.00        30\n",
    "                      SpecificationofUse       0.34      0.89      0.49        79\n",
    "     SpecificationofUse_JointReplacement       0.00      0.00      0.00        44\n",
    "                  AnatomicalTarget_Torso       0.00      0.00      0.00        35\n",
    "         AnatomicalTarget_UpperExtremity       0.00      0.00      0.00        31\n",
    "                      Imaging_Ultrasound       0.00      0.00      0.00        32\n",
    "                              Imaging_CT       0.32      0.25      0.28        59\n",
    "          AnalysisAndModeling_3DModeling       0.28      0.80      0.42        71\n",
    "                          SurgicalMethod       0.00      0.00      0.00        40\n",
    "AnatomicalTarget_UpperExtremity_Shoulder       0.00      0.00      0.00        23\n",
    "    AnatomicalTarget_LowerExtremity_Knee       0.34      1.00      0.51        82\n",
    "           PersonalizedProduct_Guide/Jig       0.49      1.00      0.66       120\n",
    "         AnatomicalTarget_LowerExtremity       0.47      1.00      0.63       113\n",
    "     Manufacturing_AdditiveManufacturing       0.00      0.00      0.00        38\n",
    "\n",
    "                               micro avg       0.44      0.69      0.54      1505\n",
    "                               macro avg       0.21      0.45      0.28      1505\n",
    "                            weighted avg       0.34      0.69      0.45      1505\n",
    "                             samples avg       0.44      0.73      0.52      1505"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Albert base w/ 256 length sequences (claims + abstract)                \n",
    "    \n",
    "    precision    recall  f1-score   support\n",
    "\n",
    "         AnatomicalTarget_LowerExtremity       0.47      1.00      0.63       113\n",
    "     Manufacturing_AdditiveManufacturing       0.67      0.05      0.10        38\n",
    "                                 Imaging       0.55      1.00      0.71       133\n",
    "                          SurgicalMethod       0.00      0.00      0.00        40\n",
    "AnatomicalTarget_UpperExtremity_Shoulder       0.18      0.13      0.15        23\n",
    "              SpecificationofUse_Disease       0.00      0.00      0.00        30\n",
    "    AnatomicalTarget_LowerExtremity_Knee       0.45      0.40      0.43        82\n",
    "                      SpecificationofUse       0.35      0.95      0.52        79\n",
    "         AnatomicalTarget_UpperExtremity       0.00      0.00      0.00        31\n",
    "            AnatomicalTarget_Torso_Spine       0.00      0.00      0.00        21\n",
    "             PersonalizedProduct_Implant       0.51      1.00      0.68       124\n",
    "                     AnalysisAndModeling       0.38      0.65      0.48        84\n",
    "          AnalysisAndModeling_3DModeling       0.33      0.68      0.44        71\n",
    "                  AnatomicalTarget_Torso       0.00      0.00      0.00        35\n",
    "     SpecificationofUse_JointReplacement       0.18      0.68      0.28        44\n",
    "                        AnatomicalTarget       0.67      1.00      0.81       164\n",
    "                           Manufacturing       0.32      0.87      0.47        83\n",
    "                             Imaging_MRI       0.26      0.15      0.19        59\n",
    "                      Imaging_Ultrasound       0.20      0.12      0.15        32\n",
    "                              Imaging_CT       0.32      0.34      0.33        59\n",
    "     AnatomicalTarget_LowerExtremity_Hip       0.14      0.03      0.04        40\n",
    "           PersonalizedProduct_Guide/Jig       0.50      1.00      0.66       120\n",
    "\n",
    "                               micro avg       0.43      0.67      0.52      1505\n",
    "                               macro avg       0.29      0.46      0.32      1505\n",
    "                            weighted avg       0.39      0.67      0.47      1505\n",
    "                             samples avg       0.43      0.70      0.51      1505"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_loss(testing_set[subset], binary_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
