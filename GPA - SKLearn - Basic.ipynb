{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import set_config\n",
    "# set_config(display='diagram') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_json(\"training_set.json.gz\", lines=True, orient=\"records\")\n",
    "\n",
    "testing_set = pd.read_json(\"testing_set.json.gz\", lines=True, orient=\"records\")\n",
    "\n",
    "subset = list(sorted(set(all_tiers_100)-set([\"PersonalizedProduct\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_embeddings = pd.read_parquet(\"/var/patentmark/citation_based_embeddings.parquet\")\n",
    "\n",
    "training_set = training_set.merge(citation_embeddings, right_index=True,left_on='publication_number', how=\"inner\" )\n",
    "testing_set = testing_set.merge(citation_embeddings, right_index=True, left_on='publication_number', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = training_set.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weights = (1 / (training_set[subset].sum() / count).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AnalysisAndModeling',\n",
       " 'AnalysisAndModeling_3DModeling',\n",
       " 'AnatomicalTarget',\n",
       " 'AnatomicalTarget_LowerExtremity',\n",
       " 'AnatomicalTarget_LowerExtremity_Hip',\n",
       " 'AnatomicalTarget_LowerExtremity_Knee',\n",
       " 'AnatomicalTarget_Torso',\n",
       " 'AnatomicalTarget_Torso_Spine',\n",
       " 'AnatomicalTarget_UpperExtremity',\n",
       " 'AnatomicalTarget_UpperExtremity_Shoulder',\n",
       " 'Imaging',\n",
       " 'Imaging_CT',\n",
       " 'Imaging_MRI',\n",
       " 'Imaging_Ultrasound',\n",
       " 'Manufacturing',\n",
       " 'Manufacturing_AdditiveManufacturing',\n",
       " 'PersonalizedProduct_Guide/Jig',\n",
       " 'PersonalizedProduct_Implant',\n",
       " 'SpecificationofUse',\n",
       " 'SpecificationofUse_Disease',\n",
       " 'SpecificationofUse_JointReplacement',\n",
       " 'SurgicalMethod']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = list(sorted(set(all_tiers_100)-set([\"PersonalizedProduct\"])))\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = training_set[subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_labels = testing_set[subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstract',\n",
       " 'all_tiers',\n",
       " 'all_tiers_100',\n",
       " 'application_kind',\n",
       " 'application_number',\n",
       " 'application_number_formatted',\n",
       " 'assignees',\n",
       " 'citation_based_embedding',\n",
       " 'citations',\n",
       " 'cited_by',\n",
       " 'claims',\n",
       " 'country_code_x',\n",
       " 'country_code_y',\n",
       " 'cpc_codes',\n",
       " 'description',\n",
       " 'embedded_cpc',\n",
       " 'embedding_v1',\n",
       " 'examiners',\n",
       " 'family_id',\n",
       " 'fi_codes',\n",
       " 'filing_date',\n",
       " 'fterm_codes',\n",
       " 'gpa_number',\n",
       " 'grant_date',\n",
       " 'inventors',\n",
       " 'kind',\n",
       " 'kind_code',\n",
       " 'padded_serial',\n",
       " 'pct_number',\n",
       " 'priority_date',\n",
       " 'publication_date',\n",
       " 'publication_number',\n",
       " 'serial_x',\n",
       " 'serial_y',\n",
       " 'similar_npl',\n",
       " 'similar_patents',\n",
       " 'tier1_tags',\n",
       " 'tier1_tier2_tags',\n",
       " 'tier2_100',\n",
       " 'tier3_100',\n",
       " 'title',\n",
       " 'top_terms',\n",
       " 'url',\n",
       " 'uspc_codes'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(training_set.columns) - set(all_tiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [prosthesis, member, coupling portion, portion...\n",
       "1      [femur, tibia, implant, leg, patient, portion,...\n",
       "2      [lateral, femur, patient, body, medial, slot, ...\n",
       "3      [glenoid, virtual, alignment pin, patient, sca...\n",
       "4      [bone, surface, patient, resection, jig, use, ...\n",
       "                             ...                        \n",
       "965    [patient, guide, device, specific, figs, surgi...\n",
       "966    [bone, ablating device, data set, control data...\n",
       "967    [method, bone, medial, patient, template, late...\n",
       "969    [patient, adapted, surface, surface model, imp...\n",
       "970    [polymer, monomers, modulus, thiol, multifunct...\n",
       "Name: top_terms, Length: 927, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.top_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/anaconda3/envs/phenetics/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.23.2 when using version 0.22. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      [0.09129103335241477, -0.8074875394503276, -0....\n",
       "1      [-0.0626441298850945, -0.8264780470303127, -0....\n",
       "2      [-0.2087969978650411, -0.8326806823412577, -0....\n",
       "3      [0.020394775830209256, -0.8215901732444764, -0...\n",
       "4      [-0.26043402403593063, -0.6891247034072876, -0...\n",
       "                             ...                        \n",
       "238    [-0.23802674313386282, -0.628900408744812, -0....\n",
       "239    [-0.3754243354002635, -0.6894144614537557, -0....\n",
       "240    [-0.12913421913981438, -0.6960149183869362, -0...\n",
       "241    [-0.3880331997688, -0.702021429171929, -0.2717...\n",
       "242    [-0.2977850042283535, -0.7015813589096069, -0....\n",
       "Name: embedded_cpc, Length: 234, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpc_embeddings = np.fromfile(\"/home/martin/patentmark/cpc.node2vec.emb.32d.bin\", dtype=np.float32).reshape((-1,32))\n",
    "\n",
    "import joblib\n",
    "cpc_labelizer = joblib.load('./node2id.joblib')\n",
    "cpc_lookup = {c: n for n, c in enumerate(cpc_labelizer.classes_)}\n",
    "\n",
    "@f.collecting\n",
    "def convert_cpc_codes(codes):\n",
    "    for code in codes:\n",
    "        if code in cpc_lookup:\n",
    "            yield cpc_lookup[code]\n",
    "    \n",
    "def embed_cpc_codes(codes):\n",
    "    embedding = np.zeros(32)\n",
    "    converted = convert_cpc_codes(codes)\n",
    "    \n",
    "    if not converted:\n",
    "        return embedding\n",
    "    \n",
    "    for code_id in converted:\n",
    "        embedding = embedding + cpc_embeddings[code_id]\n",
    "        \n",
    "    return embedding / len(converted)\n",
    "\n",
    "training_set['embedded_cpc'] = training_set.cpc_codes.apply(embed_cpc_codes)\n",
    "training_set.embedded_cpc\n",
    "\n",
    "testing_set['embedded_cpc'] = testing_set.cpc_codes.apply(embed_cpc_codes)\n",
    "testing_set.embedded_cpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import FeatureExtractionPipeline, AutoModel, AutoTokenizer\n",
    "# transformer_model = AutoModel.from_pretrained(\"bertForPatents/\", gradient_checkpointing=True)\n",
    "# transformer_tokenizer = AutoTokenizer.from_pretrained(\"bertForPatents/\")\n",
    "# transformer = FeatureExtractionPipeline(transformer_model, tokenizer=transformer_tokenizer, device=0)\n",
    "\n",
    "import sentence_transformers as st\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# model_name = \"/home/martin/patentmark/patentmark-charting-app/vectors/sPatent-v2/\"\n",
    "# text_embedder = SentenceTransformer(model_name)\n",
    "model_name = \"bertForPatents/\"\n",
    "word_embedding_model = st.models.Transformer(model_name)\n",
    "pooling_model = st.models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                               pooling_mode_mean_tokens=False,\n",
    "                               pooling_mode_cls_token=True,\n",
    "                               pooling_mode_max_tokens=False)\n",
    "text_embedder = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerFeatures(sklearn.base.BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return text_embedder.encode(X)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorPassthrough(sklearn.base.BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array(X.values.tolist())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_default_settings = {\n",
    "    'lowercase': True, \n",
    "    'strip_accents': 'ascii',\n",
    "    'stop_words' : stopwords,\n",
    "    'min_df': 5,\n",
    "    #'max_df': 0.5#,\n",
    "    #'ngram_range': (1,3)\n",
    "}\n",
    "\n",
    "column_prep = ColumnTransformer([\n",
    "#      ('top_terms',\n",
    "#       CountVectorizer(analyzer=iden, binary=True, min_df=2),\n",
    "#      'top_terms'\n",
    "#      ),\n",
    "#      ('cited_by',\n",
    "#       CountVectorizer(analyzer=iden, binary=True, min_df=2),\n",
    "#      'cited_by'\n",
    "#      ),\n",
    "#     ('inventors',\n",
    "#       CountVectorizer(analyzer=iden, binary=True, min_df=2),\n",
    "#      'inventors'\n",
    "#      ),\n",
    "#      ('citations',\n",
    "#        CountVectorizer(analyzer=iden, binary=True, min_df=2),\n",
    "#       'citations'\n",
    "#       ),\n",
    "# #         ('similar_npl',\n",
    "# #       CountVectorizer(analyzer=lambda x:x, min_df=2),\n",
    "# #      'similar_npl'\n",
    "# #      ),\n",
    "#         ('similar_patents',\n",
    "#       CountVectorizer(analyzer=iden, binary=True, min_df=2),\n",
    "#      'similar_patents'\n",
    "#      )\n",
    "#   ,\n",
    "#      ('cpc',\n",
    "#       CountVectorizer(analyzer=cpc_split, binary=True, min_df=2),\n",
    "#      'cpc_codes'\n",
    "#      ),\n",
    "    ('citation_based_embedding', VectorPassthrough(), 'citation_based_embedding'),\n",
    "    ('embedded_cpc', \n",
    "     VectorPassthrough(),\n",
    "     'embedded_cpc'\n",
    "    ),\n",
    "    ('embedding_v1',\n",
    "     VectorPassthrough(),\n",
    "     'embedding_v1'\n",
    "    ),\n",
    "#     ('transformer_abstract',\n",
    "#     TransformerFeatures(),\n",
    "#      'abstract'\n",
    "#     ),\n",
    "    ('transformer_claims',\n",
    "     TransformerFeatures(),\n",
    "     'claims'\n",
    "    )\n",
    "], verbose=False, n_jobs=1)\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "pipeline = Pipeline(steps=[('columns', column_prep), ('norm', Normalizer())])\n",
    "    \n",
    "#     ('abstract_tfidf', \n",
    "#     TfidfVectorizer(**tfidf_default_settings),\n",
    "#    'abstract'),\n",
    "#     ('claims_tfidf',\n",
    "#      TfidfVectorizer(**tfidf_default_settings),\n",
    "#      'claims'\n",
    "#     ),\n",
    "#     ('description_tfidf',\n",
    "#      TfidfVectorizer(**tfidf_default_settings),\n",
    "#      'description'\n",
    "#     )\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "312",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 312",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-17f135cff51d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmlb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \"\"\"\n\u001b[1;32m    382\u001b[0m         \u001b[0mlast_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    385\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;31m# Fit or load from cache the current transfomer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    310\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, y, func, fitted)\u001b[0m\n\u001b[1;32m    446\u001b[0m             self._iter(fitted=fitted, replace_strings=True))\n\u001b[1;32m    447\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             return Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    449\u001b[0m                 delayed(func)(\n\u001b[1;32m    450\u001b[0m                     \u001b[0mtransformer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-93-368221f7d414>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext_embedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, is_pretokenized, device, num_workers)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mall_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mlength_sorted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_text_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msen\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0msentences_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlength_sorted_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0minp_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncodeDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_tokenized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_pretokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0minp_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_batching_collate_text_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mall_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mlength_sorted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_text_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msen\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0msentences_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlength_sorted_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0minp_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncodeDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_tokenized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_pretokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0minp_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_batching_collate_text_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phenetics/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 312"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "import util\n",
    "X_train = pipeline.fit_transform(training_set)\n",
    "X_test = pipeline.transform(testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = mlb.fit_transform(training_set[subset].apply(util.array_labels, axis=1))\n",
    "y_test = mlb.transform(testing_set[subset].apply(util.array_labels, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, SelectFromModel\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_jobs=-1, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          precision    recall  f1-score   support\n",
      "\n",
      "                     AnalysisAndModeling       0.26      0.09      0.13        78\n",
      "          AnalysisAndModeling_3DModeling       0.15      0.03      0.05        65\n",
      "                        AnatomicalTarget       0.70      0.87      0.78       158\n",
      "         AnatomicalTarget_LowerExtremity       0.52      0.41      0.46       108\n",
      "     AnatomicalTarget_LowerExtremity_Hip       0.00      0.00      0.00        38\n",
      "    AnatomicalTarget_LowerExtremity_Knee       0.64      0.21      0.31        78\n",
      "                  AnatomicalTarget_Torso       0.00      0.00      0.00        34\n",
      "            AnatomicalTarget_Torso_Spine       0.00      0.00      0.00        20\n",
      "         AnatomicalTarget_UpperExtremity       0.00      0.00      0.00        29\n",
      "AnatomicalTarget_UpperExtremity_Shoulder       0.00      0.00      0.00        21\n",
      "                                 Imaging       0.63      0.76      0.69       128\n",
      "                              Imaging_CT       0.33      0.09      0.14        56\n",
      "                             Imaging_MRI       0.50      0.12      0.20        56\n",
      "                      Imaging_Ultrasound       0.29      0.06      0.10        32\n",
      "                           Manufacturing       0.34      0.25      0.29        77\n",
      "     Manufacturing_AdditiveManufacturing       0.00      0.00      0.00        35\n",
      "           PersonalizedProduct_Guide/Jig       0.53      0.30      0.38       113\n",
      "             PersonalizedProduct_Implant       0.56      0.74      0.64       122\n",
      "                      SpecificationofUse       0.39      0.22      0.28        77\n",
      "              SpecificationofUse_Disease       0.20      0.03      0.06        30\n",
      "     SpecificationofUse_JointReplacement       0.33      0.07      0.12        42\n",
      "                          SurgicalMethod       0.83      0.13      0.22        39\n",
      "\n",
      "                               micro avg       0.55      0.34      0.42      1436\n",
      "                               macro avg       0.33      0.20      0.22      1436\n",
      "                            weighted avg       0.43      0.34      0.35      1436\n",
      "                             samples avg       0.56      0.37      0.41      1436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/anaconda3/envs/phenetics/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/martin/anaconda3/envs/phenetics/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test, predictions, target_names=subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from skopt import *\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "param_grid = {\n",
    "    #'rf__bootstrap': [True, False],\n",
    "    'max_depth': (10, 1000), #[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 125, 150, 175, 200, 250, 300, 350, 400, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': (1, 12),\n",
    " 'min_samples_split': (2, 12),\n",
    " 'n_estimators': (5, 1000)          \n",
    "             }\n",
    "\n",
    "\n",
    "# param_grid = {\n",
    "#     'svd__n_components': Integer(64,10000),\n",
    "#     'svc__estimator__C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "#     'svc__estimator__gamma': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "#     'svc__estimator__degree': Integer(1,8),\n",
    "#     'svc__estimator__kernel': Categorical(['linear', 'poly', 'rbf']),\n",
    "# }\n",
    "\n",
    "# param_grid = {\n",
    "# #  'svd__n_components': np.arange(64, 5000, 100),\n",
    "#  'knn__leaf_size': np.arange(1, 50, 1),\n",
    "#  'knn__metric': ['minkowski', 'euclidean'],\n",
    "#  'knn__n_neighbors': [2,3,4,5,6,7,8,9,10,11,12],\n",
    "#  'knn__weights': ['distance', 'uniform']\n",
    "# }\n",
    "model = RandomForestClassifier()\n",
    "search = BayesSearchCV(model, param_grid, n_iter=50, n_points=3, pre_dispatch=36, refit=True, cv=3, verbose=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.utils import CallbackIOWrapper\n",
    "\n",
    "with tqdm(total=search.total_iterations) as pbar:\n",
    "    def on_step(optim_result):\n",
    "        print(optim_result)\n",
    "        pbar.update(9)\n",
    "        return False\n",
    "    search.fit(X_train, y_train, callback=on_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = search.estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(testing_labels, predictions, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_loss(testing_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(pipe, testing_set, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictions = search.best_estimator_.predict(X[:,features_set])\n",
    "print(classification_report(training_labels, training_predictions, target_names=subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt import *\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "param_grid = {\n",
    "    #'rf__bootstrap': [True, False],\n",
    "    'rf__max_depth': (10, 1000), #[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 125, 150, 175, 200, 250, 300, 350, 400, None],\n",
    " #'rf__max_features': ['auto', 'sqrt'],\n",
    " 'rf__min_samples_leaf': (1, 12),\n",
    " 'rf__min_samples_split': (2, 12),\n",
    " 'rf__n_estimators': (5, 1000)          \n",
    "             }\n",
    "\n",
    "\n",
    "# param_grid = {\n",
    "#     'svd__n_components': Integer(64,10000),\n",
    "#     'svc__estimator__C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "#     'svc__estimator__gamma': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "#     'svc__estimator__degree': Integer(1,8),\n",
    "#     'svc__estimator__kernel': Categorical(['linear', 'poly', 'rbf']),\n",
    "# }\n",
    "\n",
    "# param_grid = {\n",
    "# #  'svd__n_components': np.arange(64, 5000, 100),\n",
    "#  'knn__leaf_size': np.arange(1, 50, 1),\n",
    "#  'knn__metric': ['minkowski', 'euclidean'],\n",
    "#  'knn__n_neighbors': [2,3,4,5,6,7,8,9,10,11,12],\n",
    "#  'knn__weights': ['distance', 'uniform']\n",
    "# }\n",
    "search = BayesSearchCV(pipe, param_grid, n_iter=50, n_points=3, pre_dispatch=36, refit=True, cv=3, verbose=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.utils import CallbackIOWrapper\n",
    "\n",
    "with tqdm(total=search.total_iterations) as pbar:\n",
    "    def on_step(optim_result):\n",
    "        print(optim_result)\n",
    "        pbar.update(9)\n",
    "        return False\n",
    "    search.fit(training_set, training_labels, callback=on_step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(search.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "#pipe.fit(training_set, training_labels)\n",
    "#predictions = pipe.predict(testing_set)\n",
    "predictions = search.best_estimator_.predict(Xtest[:,features_set])\n",
    "print(classification_report(testing_labels, predictions, target_names=subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "#pipe.fit(training_set, training_labels)\n",
    "#predictions = pipe.predict(testing_set)\n",
    "predictions = search.best_estimator_.predict(testing_set)\n",
    "print(classification_report(testing_labels, predictions, target_names=all_tiers_100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "#pipe.fit(training_set, training_labels)\n",
    "predictions = pipe.predict(testing_set)\n",
    "print(classification_report(testing_labels, predictions, target_names=all_tiers_100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions = search.best_estimator_.predict(training_set)\n",
    "print(classification_report(training_labels, predictions, target_names=subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  Guessing Baseline\n",
    "\n",
    "                                      precision    recall  f1-score   support\n",
    "\n",
    "                 AnalysisAndModeling       0.31      0.32      0.32        84\n",
    "                    AnatomicalTarget       0.63      0.63      0.63       164\n",
    "                             Imaging       0.57      0.56      0.56       133\n",
    "                       Manufacturing       0.38      0.48      0.43        83\n",
    "                  SpecificationofUse       0.33      0.33      0.33        79\n",
    "                      SurgicalMethod       0.19      0.20      0.20        40\n",
    "      AnalysisAndModeling_3DModeling       0.22      0.21      0.22        71\n",
    "     AnatomicalTarget_LowerExtremity       0.45      0.43      0.44       113\n",
    "              AnatomicalTarget_Torso       0.19      0.17      0.18        35\n",
    "     AnatomicalTarget_UpperExtremity       0.26      0.26      0.26        31\n",
    "                          Imaging_CT       0.14      0.19      0.16        59\n",
    "                         Imaging_MRI       0.24      0.20      0.22        59\n",
    "                  Imaging_Ultrasound       0.17      0.19      0.18        32\n",
    " Manufacturing_AdditiveManufacturing       0.24      0.24      0.24        38\n",
    "       PersonalizedProduct_Guide/Jig       0.55      0.46      0.50       120\n",
    "         PersonalizedProduct_Implant       0.49      0.53      0.51       124\n",
    "          SpecificationofUse_Disease       0.19      0.20      0.20        30\n",
    " SpecificationofUse_JointReplacement       0.14      0.23      0.17        44\n",
    " AnatomicalTarget_LowerExtremity_Hip       0.21      0.17      0.19        40\n",
    "AnatomicalTarget_LowerExtremity_Knee       0.32      0.34      0.33        82\n",
    "\n",
    "                           micro avg       0.38      0.39      0.38      1461\n",
    "                           macro avg       0.31      0.32      0.31      1461\n",
    "                        weighted avg       0.38      0.39      0.39      1461\n",
    "                         samples avg       0.38      0.40      0.37      1461"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF\n",
    "\n",
    " {'rf__bootstrap': False,\n",
    " 'rf__ccp_alpha': 0.0,\n",
    " 'rf__class_weight': None,\n",
    " 'rf__criterion': 'gini',\n",
    " 'rf__max_depth': 150,\n",
    " 'rf__max_features': 'sqrt',\n",
    " 'rf__max_leaf_nodes': None,\n",
    " 'rf__max_samples': None,\n",
    " 'rf__min_impurity_decrease': 0.0,\n",
    " 'rf__min_impurity_split': None,\n",
    " 'rf__min_samples_leaf': 1,\n",
    " 'rf__min_samples_split': 2,\n",
    " 'rf__min_weight_fraction_leaf': 0.0,\n",
    " 'rf__n_estimators': 200,\n",
    " 'rf__n_jobs': None,\n",
    " 'rf__oob_score': False,\n",
    " 'rf__random_state': None,\n",
    " 'rf__verbose': 0,\n",
    " 'rf__warm_start': False}\n",
    "\n",
    "                                      precision    recall  f1-score   support\n",
    "\n",
    "                 AnalysisAndModeling       0.43      0.24      0.31        84\n",
    "                    AnatomicalTarget       0.70      0.78      0.74       164\n",
    "                             Imaging       0.60      0.59      0.60       133\n",
    "                       Manufacturing       0.37      0.25      0.30        83\n",
    "                  SpecificationofUse       0.42      0.32      0.36        79\n",
    "                      SurgicalMethod       0.71      0.30      0.42        40\n",
    "      AnalysisAndModeling_3DModeling       0.38      0.18      0.25        71\n",
    "     AnatomicalTarget_LowerExtremity       0.53      0.46      0.49       113\n",
    "              AnatomicalTarget_Torso       0.08      0.03      0.04        35\n",
    "     AnatomicalTarget_UpperExtremity       0.11      0.03      0.05        31\n",
    "                          Imaging_CT       0.18      0.10      0.13        59\n",
    "                         Imaging_MRI       0.28      0.14      0.18        59\n",
    "                  Imaging_Ultrasound       0.00      0.00      0.00        32\n",
    " Manufacturing_AdditiveManufacturing       0.23      0.08      0.12        38\n",
    "       PersonalizedProduct_Guide/Jig       0.64      0.41      0.50       120\n",
    "         PersonalizedProduct_Implant       0.59      0.74      0.66       124\n",
    "          SpecificationofUse_Disease       0.06      0.03      0.04        30\n",
    " SpecificationofUse_JointReplacement       0.21      0.16      0.18        44\n",
    " AnatomicalTarget_LowerExtremity_Hip       0.26      0.12      0.17        40\n",
    "AnatomicalTarget_LowerExtremity_Knee       0.47      0.33      0.39        82\n",
    "\n",
    "                           micro avg       0.50      0.38      0.43      1461\n",
    "                           macro avg       0.36      0.26      0.30      1461\n",
    "                        weighted avg       0.45      0.38      0.40      1461\n",
    "                         samples avg       0.53      0.41      0.43      1461\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "\n",
    " 'knn__algorithm': 'auto',\n",
    " 'knn__leaf_size': 30,\n",
    " 'knn__metric': 'euclidean',\n",
    " 'knn__metric_params': None,\n",
    " 'knn__n_jobs': None,\n",
    " 'knn__n_neighbors': 2,\n",
    " 'knn__p': 2,\n",
    " 'knn__weights': 'distance'\n",
    "                                      precision    recall  f1-score   support\n",
    "\n",
    "                 AnalysisAndModeling       0.38      0.43      0.40        84\n",
    "                    AnatomicalTarget       0.71      0.60      0.65       164\n",
    "                             Imaging       0.63      0.62      0.62       133\n",
    "                       Manufacturing       0.34      0.37      0.36        83\n",
    "                  SpecificationofUse       0.34      0.47      0.39        79\n",
    "                      SurgicalMethod       0.39      0.30      0.34        40\n",
    "      AnalysisAndModeling_3DModeling       0.35      0.38      0.36        71\n",
    "     AnatomicalTarget_LowerExtremity       0.60      0.50      0.54       113\n",
    "              AnatomicalTarget_Torso       0.24      0.11      0.15        35\n",
    "     AnatomicalTarget_UpperExtremity       0.16      0.16      0.16        31\n",
    "                          Imaging_CT       0.24      0.32      0.27        59\n",
    "                         Imaging_MRI       0.24      0.32      0.28        59\n",
    "                  Imaging_Ultrasound       0.16      0.28      0.21        32\n",
    " Manufacturing_AdditiveManufacturing       0.18      0.13      0.15        38\n",
    "       PersonalizedProduct_Guide/Jig       0.59      0.39      0.47       120\n",
    "         PersonalizedProduct_Implant       0.56      0.76      0.64       124\n",
    "          SpecificationofUse_Disease       0.19      0.33      0.24        30\n",
    " SpecificationofUse_JointReplacement       0.12      0.14      0.13        44\n",
    " AnatomicalTarget_LowerExtremity_Hip       0.33      0.30      0.32        40\n",
    "AnatomicalTarget_LowerExtremity_Knee       0.48      0.39      0.43        82\n",
    "\n",
    "                           micro avg       0.43      0.44      0.43      1461\n",
    "                           macro avg       0.36      0.37      0.36      1461\n",
    "                        weighted avg       0.45      0.44      0.44      1461\n",
    "                         samples avg       0.45      0.46      0.41      1461"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN + SVD\n",
    "\n",
    " precision    recall  f1-score   support\n",
    "\n",
    "                 AnalysisAndModeling       0.38      0.43      0.40        84\n",
    "                    AnatomicalTarget       0.71      0.60      0.65       164\n",
    "                             Imaging       0.63      0.62      0.62       133\n",
    "                       Manufacturing       0.34      0.37      0.36        83\n",
    "                  SpecificationofUse       0.34      0.47      0.39        79\n",
    "                      SurgicalMethod       0.39      0.30      0.34        40\n",
    "      AnalysisAndModeling_3DModeling       0.35      0.38      0.36        71\n",
    "     AnatomicalTarget_LowerExtremity       0.60      0.50      0.54       113\n",
    "              AnatomicalTarget_Torso       0.24      0.11      0.15        35\n",
    "     AnatomicalTarget_UpperExtremity       0.16      0.16      0.16        31\n",
    "                          Imaging_CT       0.24      0.32      0.27        59\n",
    "                         Imaging_MRI       0.24      0.32      0.28        59\n",
    "                  Imaging_Ultrasound       0.16      0.28      0.21        32\n",
    " Manufacturing_AdditiveManufacturing       0.18      0.13      0.15        38\n",
    "       PersonalizedProduct_Guide/Jig       0.59      0.39      0.47       120\n",
    "         PersonalizedProduct_Implant       0.56      0.76      0.64       124\n",
    "          SpecificationofUse_Disease       0.19      0.33      0.24        30\n",
    " SpecificationofUse_JointReplacement       0.12      0.14      0.13        44\n",
    " AnatomicalTarget_LowerExtremity_Hip       0.33      0.30      0.32        40\n",
    "AnatomicalTarget_LowerExtremity_Knee       0.48      0.39      0.43        82\n",
    "\n",
    "                           micro avg       0.43      0.44      0.43      1461\n",
    "                           macro avg       0.36      0.37      0.36      1461\n",
    "                        weighted avg       0.45      0.44      0.44      1461\n",
    "                         samples avg       0.45      0.46      0.41      1461\n",
    "\n",
    "'svd__algorithm': 'randomized',\n",
    " 'svd__n_components': 2564,\n",
    " 'svd__n_iter': 5,\n",
    " 'svd__random_state': 42,\n",
    " 'svd__tol': 0.0,\n",
    " 'knn__algorithm': 'auto',\n",
    " 'knn__leaf_size': 30,\n",
    " 'knn__metric': 'euclidean',\n",
    " 'knn__metric_params': None,\n",
    " 'knn__n_jobs': None,\n",
    " 'knn__n_neighbors': 2,\n",
    " 'knn__p': 2,\n",
    " 'knn__weights': 'distance'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
