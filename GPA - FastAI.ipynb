{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from catalyst import dl\n",
    "from catalyst import dl, utils\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import logging\n",
    "\n",
    "import fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set( np.where(y_true[i])[0] )\n",
    "        set_pred = set( np.where(y_pred[i])[0] )\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
    "                    float( len(set_true.union(set_pred)) )\n",
    "        acc_list.append(tmp_a)\n",
    "    return np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_json(\"training_set.json.gz\", lines=True, orient=\"records\")\n",
    "testing_set = pd.read_json(\"testing_set.json.gz\", lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AnatomicalTarget_Torso',\n",
       " 'Manufacturing',\n",
       " 'Imaging_Ultrasound',\n",
       " 'AnatomicalTarget',\n",
       " 'PersonalizedProduct_Guide/Jig',\n",
       " 'AnalysisAndModeling_3DModeling',\n",
       " 'Manufacturing_AdditiveManufacturing',\n",
       " 'AnatomicalTarget_Torso_Spine',\n",
       " 'AnatomicalTarget_LowerExtremity_Hip',\n",
       " 'PersonalizedProduct_Implant',\n",
       " 'Imaging_CT',\n",
       " 'AnatomicalTarget_LowerExtremity_Knee',\n",
       " 'SpecificationofUse',\n",
       " 'AnalysisAndModeling',\n",
       " 'AnatomicalTarget_UpperExtremity',\n",
       " 'Imaging',\n",
       " 'SpecificationofUse_Disease',\n",
       " 'SpecificationofUse_JointReplacement',\n",
       " 'AnatomicalTarget_UpperExtremity_Shoulder',\n",
       " 'SurgicalMethod',\n",
       " 'AnatomicalTarget_LowerExtremity',\n",
       " 'Imaging_MRI']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = list(set(all_tiers_100)-set([\"PersonalizedProduct\"]))\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['labels']=training_set[subset].astype(int).values.tolist()\n",
    "testing_set['labels']=testing_set[subset].astype(int).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_set['label'] = training_set.AnalysisAndModeling.astype(int)\n",
    "# testing_set['label'] = testing_set.AnalysisAndModeling.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_set.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data = Dataset.from_pandas(training_set, split=\"training\")\n",
    "#testing_data = Dataset.from_pandas(testing_set, split=\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 8\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-5\n",
    "SEED = 17\n",
    "PRED_THRES = 0.4\n",
    "ACCUM_STEPS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = \"allenai/longformer-base-4096\"\n",
    "model_name = \"albert-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        \n",
    "        self.claims = dataframe.claims\n",
    "        self.abstracts = dataframe.abstract\n",
    "        \n",
    "        self.targets = self.data.labels\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def tokenize(self, text, prefix=\"\"):\n",
    "        text = str(text)\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            f\"input_ids\": torch.tensor(ids, dtype=torch.long),\n",
    "            f\"attention_mask\": torch.tensor(mask, dtype=torch.long),\n",
    "            f\"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
    "        }\n",
    "    \n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        abstract = self.tokenize(self.abstracts[index], prefix=\"abstract_\")\n",
    "        claims = self.tokenize(self.claims[index], prefix=\"claims_\")\n",
    "        \n",
    "        return {\"abstract\": abstract, \"claims\": claims, 'targets': torch.tensor(self.targets[index], dtype=torch.float)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = MultiLabelDataset(training_set, tokenizer, MAX_LEN)\n",
    "testing_dataset = MultiLabelDataset(testing_set, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "data = fastai.DataLoaders\n",
    "\n",
    "training_loader = DataLoader(training_dataset, **train_params)\n",
    "testing_loader = DataLoader(testing_dataset, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\"train\": training_loader, \"valid\": testing_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModel.from_pretrained(model_name)#, gradient_checkpointing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlbertModel(\n",
       "  (embeddings): AlbertEmbeddings(\n",
       "    (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 128)\n",
       "    (token_type_embeddings): Embedding(2, 128)\n",
       "    (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (encoder): AlbertTransformer(\n",
       "    (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "    (albert_layer_groups): ModuleList(\n",
       "      (0): AlbertLayerGroup(\n",
       "        (albert_layers): ModuleList(\n",
       "          (0): AlbertLayer(\n",
       "            (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (attention): AlbertAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (attention_dropout): Dropout(p=0, inplace=False)\n",
       "              (output_dropout): Dropout(p=0, inplace=False)\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (pooler_activation): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.pooler.out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = AutoModel.from_pretrained(model_name)\n",
    "        self.pre_classifier = torch.nn.Linear(base_model.pooler.out_features*2, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.classifier = torch.nn.Linear(768, len(subset))\n",
    "\n",
    "    def forward(self, abstract, claims ):\n",
    "        abstract_emb = self.l1(input_ids=abstract[\"input_ids\"], attention_mask=abstract[\"attention_mask\"])\n",
    "        abstract_emb = abstract_emb[0][:, 0]\n",
    "        claim_emb = self.l1(input_ids=claims[\"input_ids\"], attention_mask=claims[\"attention_mask\"])\n",
    "        claim_emb = claim_emb[0][:, 0]\n",
    "        \n",
    "        text_emb = torch.cat((abstract_emb, claim_emb), 1)\n",
    "        \n",
    "        pooler = self.pre_classifier(text_emb)\n",
    "        pooler = torch.nn.Sigmoid()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = utils.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "logdir=\"logdir/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 23398), started 0:00:54 ago. (Use '!kill 23398' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-84e7d4e12896742e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-84e7d4e12896742e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logdir/fit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catalyst.contrib as contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/100 * Epoch (train):   0% 0/122 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100 * Epoch (train): 100% 122/122 [01:04<00:00,  1.89it/s, loss=1.052, multi_label_accuracy=0.773]\n",
      "1/100 * Epoch (valid): 100% 31/31 [00:07<00:00,  3.99it/s, loss=0.991, multi_label_accuracy=0.788]\n",
      "[2020-11-25 09:18:50,020] \n",
      "1/100 * Epoch 1 (_base): lr=1.000e-05 | momentum=0.9000\n",
      "1/100 * Epoch 1 (train): loss=1.0735 | multi_label_accuracy=0.7140\n",
      "1/100 * Epoch 1 (valid): loss=1.0081 | multi_label_accuracy=0.7402\n",
      "2/100 * Epoch (train): 100% 122/122 [01:07<00:00,  1.80it/s, loss=1.063, multi_label_accuracy=0.670]\n",
      "2/100 * Epoch (valid): 100% 31/31 [00:08<00:00,  3.68it/s, loss=0.981, multi_label_accuracy=0.773]\n",
      "[2020-11-25 09:20:06,553] \n",
      "2/100 * Epoch 2 (_base): lr=1.000e-05 | momentum=0.9000\n",
      "2/100 * Epoch 2 (train): loss=1.0491 | multi_label_accuracy=0.7322\n",
      "2/100 * Epoch 2 (valid): loss=1.0025 | multi_label_accuracy=0.7403\n",
      "3/100 * Epoch (train): 100% 122/122 [01:07<00:00,  1.81it/s, loss=0.999, multi_label_accuracy=0.750]\n",
      "3/100 * Epoch (valid): 100% 31/31 [00:08<00:00,  3.86it/s, loss=0.983, multi_label_accuracy=0.773]\n",
      "[2020-11-25 09:21:23,678] \n",
      "3/100 * Epoch 3 (_base): lr=1.000e-05 | momentum=0.9000\n",
      "3/100 * Epoch 3 (train): loss=1.0406 | multi_label_accuracy=0.7341\n",
      "3/100 * Epoch 3 (valid): loss=1.0028 | multi_label_accuracy=0.7403\n",
      "4/100 * Epoch (train): 100% 122/122 [01:07<00:00,  1.80it/s, loss=1.024, multi_label_accuracy=0.773]\n",
      "4/100 * Epoch (valid): 100% 31/31 [00:07<00:00,  3.93it/s, loss=0.983, multi_label_accuracy=0.773]\n",
      "[2020-11-25 09:22:40,153] \n",
      "4/100 * Epoch 4 (_base): lr=1.000e-05 | momentum=0.9000\n",
      "4/100 * Epoch 4 (train): loss=1.0385 | multi_label_accuracy=0.7342\n",
      "4/100 * Epoch 4 (valid): loss=1.0048 | multi_label_accuracy=0.7403\n",
      "Early stop at 4 epoch\n",
      "Top best models:\n",
      "logdir/fit/20201125-091731/checkpoints/train.2.pth\t1.0025\n"
     ]
    }
   ],
   "source": [
    "#criterion = torch.nn.BCEWithLogitsLoss()\n",
    "criterion = contrib.nn.criterion.LovaszLossMultiLabel()\n",
    "optimizer = torch.optim.AdamW(params =  model.parameters(), lr=LEARNING_RATE)\n",
    "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [2])\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "#lrfinder = dl.LRFinder(final_lr=1)\n",
    "\n",
    "runner = dl.SupervisedRunner(input_key=(\"abstract\", \"claims\"))\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    #scheduler=scheduler,\n",
    "    loaders=loaders,\n",
    "    logdir=logdir,\n",
    "    num_epochs=EPOCHS,\n",
    "    callbacks=[\n",
    "               dl.MultiLabelAccuracyCallback(threshold=PRED_THRES, activation=\"None\"),\n",
    "               dl.EarlyStoppingCallback(patience=2, metric=\"loss\", minimize=True),\n",
    "               #dl.TensorboardLogger(),\n",
    "               #dl.CheckpointCallback(),\n",
    "               dl.OptimizerCallback(accumulation_steps=ACCUM_STEPS),\n",
    "               dl.ValidationManagerCallback()],\n",
    "               #lrfinder],\n",
    "               #dl.MetricManagerCallback(num_classes=len(subset), ),\n",
    "    \n",
    "    fp16=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.vstack(list(map(\n",
    "    lambda x: x[\"logits\"].cpu().numpy(), \n",
    "    runner.predict_loader(loader=loaders[\"valid\"], resume=f\"logdir/fit/20201125-091731/checkpoints/train.2.pth\")\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AnatomicalTarget_UpperExtremity</th>\n",
       "      <th>AnalysisAndModeling</th>\n",
       "      <th>Manufacturing</th>\n",
       "      <th>AnalysisAndModeling_3DModeling</th>\n",
       "      <th>SpecificationofUse_Disease</th>\n",
       "      <th>AnatomicalTarget_LowerExtremity_Knee</th>\n",
       "      <th>AnatomicalTarget_LowerExtremity_Hip</th>\n",
       "      <th>PersonalizedProduct_Implant</th>\n",
       "      <th>PersonalizedProduct_Guide/Jig</th>\n",
       "      <th>AnatomicalTarget</th>\n",
       "      <th>...</th>\n",
       "      <th>AnatomicalTarget_Torso_Spine</th>\n",
       "      <th>AnatomicalTarget_LowerExtremity</th>\n",
       "      <th>Imaging</th>\n",
       "      <th>SpecificationofUse_JointReplacement</th>\n",
       "      <th>Imaging_Ultrasound</th>\n",
       "      <th>SurgicalMethod</th>\n",
       "      <th>SpecificationofUse</th>\n",
       "      <th>Imaging_MRI</th>\n",
       "      <th>Manufacturing_AdditiveManufacturing</th>\n",
       "      <th>AnatomicalTarget_UpperExtremity_Shoulder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AnatomicalTarget_UpperExtremity  AnalysisAndModeling  Manufacturing  \\\n",
       "0                            False                 True           True   \n",
       "1                            False                 True          False   \n",
       "2                            False                False          False   \n",
       "3                            False                False          False   \n",
       "4                            False                 True           True   \n",
       "\n",
       "   AnalysisAndModeling_3DModeling  SpecificationofUse_Disease  \\\n",
       "0                           False                       False   \n",
       "1                            True                       False   \n",
       "2                           False                       False   \n",
       "3                           False                        True   \n",
       "4                           False                       False   \n",
       "\n",
       "   AnatomicalTarget_LowerExtremity_Knee  AnatomicalTarget_LowerExtremity_Hip  \\\n",
       "0                                  True                                False   \n",
       "1                                 False                                 True   \n",
       "2                                  True                                False   \n",
       "3                                 False                                False   \n",
       "4                                 False                                 True   \n",
       "\n",
       "   PersonalizedProduct_Implant  PersonalizedProduct_Guide/Jig  \\\n",
       "0                         True                          False   \n",
       "1                        False                           True   \n",
       "2                        False                           True   \n",
       "3                         True                          False   \n",
       "4                         True                          False   \n",
       "\n",
       "   AnatomicalTarget  ...  AnatomicalTarget_Torso_Spine  \\\n",
       "0              True  ...                         False   \n",
       "1              True  ...                         False   \n",
       "2              True  ...                         False   \n",
       "3             False  ...                         False   \n",
       "4              True  ...                         False   \n",
       "\n",
       "   AnatomicalTarget_LowerExtremity  Imaging  \\\n",
       "0                             True    False   \n",
       "1                             True     True   \n",
       "2                             True    False   \n",
       "3                            False     True   \n",
       "4                             True     True   \n",
       "\n",
       "   SpecificationofUse_JointReplacement  Imaging_Ultrasound  SurgicalMethod  \\\n",
       "0                                False               False           False   \n",
       "1                                False               False           False   \n",
       "2                                False               False            True   \n",
       "3                                False                True           False   \n",
       "4                                False               False           False   \n",
       "\n",
       "   SpecificationofUse  Imaging_MRI  Manufacturing_AdditiveManufacturing  \\\n",
       "0               False        False                                False   \n",
       "1               False        False                                False   \n",
       "2               False        False                                False   \n",
       "3                True         True                                False   \n",
       "4               False         True                                False   \n",
       "\n",
       "   AnatomicalTarget_UpperExtremity_Shoulder  \n",
       "0                                     False  \n",
       "1                                     False  \n",
       "2                                     False  \n",
       "3                                     False  \n",
       "4                                     False  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_set[subset].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_predictions = torch.sigmoid(torch.from_numpy(predictions)) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          precision    recall  f1-score   support\n",
      "\n",
      "         AnatomicalTarget_UpperExtremity       0.00      0.00      0.00        31\n",
      "                     AnalysisAndModeling       0.35      0.98      0.51        84\n",
      "                           Manufacturing       0.34      1.00      0.51        83\n",
      "          AnalysisAndModeling_3DModeling       0.31      0.87      0.46        71\n",
      "              SpecificationofUse_Disease       0.00      0.00      0.00        30\n",
      "    AnatomicalTarget_LowerExtremity_Knee       0.34      0.73      0.47        82\n",
      "     AnatomicalTarget_LowerExtremity_Hip       0.20      0.25      0.22        40\n",
      "             PersonalizedProduct_Implant       0.51      1.00      0.68       124\n",
      "           PersonalizedProduct_Guide/Jig       0.49      1.00      0.66       120\n",
      "                        AnatomicalTarget       0.67      1.00      0.81       164\n",
      "                              Imaging_CT       0.24      0.98      0.39        59\n",
      "                  AnatomicalTarget_Torso       0.00      0.00      0.00        35\n",
      "            AnatomicalTarget_Torso_Spine       0.00      0.00      0.00        21\n",
      "         AnatomicalTarget_LowerExtremity       0.47      1.00      0.64       113\n",
      "                                 Imaging       0.55      1.00      0.71       133\n",
      "     SpecificationofUse_JointReplacement       0.22      0.05      0.08        44\n",
      "                      Imaging_Ultrasound       0.00      0.00      0.00        32\n",
      "                          SurgicalMethod       0.00      0.00      0.00        40\n",
      "                      SpecificationofUse       0.33      0.62      0.43        79\n",
      "                             Imaging_MRI       0.27      0.93      0.42        59\n",
      "     Manufacturing_AdditiveManufacturing       0.22      0.26      0.24        38\n",
      "AnatomicalTarget_UpperExtremity_Shoulder       0.00      0.00      0.00        23\n",
      "\n",
      "                               micro avg       0.41      0.75      0.53      1505\n",
      "                               macro avg       0.25      0.53      0.33      1505\n",
      "                            weighted avg       0.36      0.75      0.48      1505\n",
      "                             samples avg       0.41      0.77      0.51      1505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "print(classification_report(testing_set[subset].astype(int), binary_predictions, target_names=subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_loss(testing_set[subset], binary_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
