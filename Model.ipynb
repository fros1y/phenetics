{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from gensim.parsing.preprocessing import strip_non_alphanum, strip_punctuation\n",
    "import torch\n",
    "import torchtext\n",
    "from sklearn.model_selection import *\n",
    "from torch import nn\n",
    "import gensim.downloader as api\n",
    "\n",
    "from torchtext.data import Field, LabelField\n",
    "from torchtext.data import BucketIterator\n",
    "from torchtext.datasets import IMDB\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import Freezer\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.pipeline import * \n",
    "from sklearn.compose import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.neural_network import *\n",
    "from sklearn.preprocessing import *\n",
    "from skorch.callbacks import ProgressBar\n",
    "from util import *\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import fse\n",
    "from fse.models import uSIF\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.utils import CallbackIOWrapper\n",
    "from skopt.space import Real, Integer\n",
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = KeyedVectors.load(\"/var/patentmark/older/patent-vectors.v4.gensim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.index2word[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "usif = uSIF(wv, workers=32, lang_freq=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_json(\"training_set.json.gz\", lines=True, orient=\"records\")\n",
    "testing_set = pd.read_json(\"testing_set.json.gz\", lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Manufacturing',\n",
       " 'SpecificationofUse',\n",
       " 'Imaging',\n",
       " 'AnalysisAndModeling',\n",
       " 'SurgicalMethod',\n",
       " 'AnatomicalTarget']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = list((set(tier1)-set([\"PersonalizedProduct\"]))&set(all_tiers_100))\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = training_set[subset]\n",
    "testing_labels = testing_set[subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_default_settings = {\n",
    "    'lowercase': True, \n",
    "    'strip_accents': 'ascii',\n",
    "    #'stop_words' : stopwords,\n",
    "    'min_df': 5,\n",
    "    'max_df': 0.5,\n",
    "    #'ngram_range': (1,3)\n",
    "}\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "#      ('top_terms', CountVectorizer(analyzer=iden, binary=True, min_df=2), 'top_terms'),\n",
    "#      ('cited_by', CountVectorizer(analyzer=iden, binary=True, min_df=2), 'cited_by'),\n",
    "#      ('inventors', CountVectorizer(analyzer=iden, binary=True, min_df=2), 'inventors'),\n",
    "#      ('citations', CountVectorizer(analyzer=citations_split, binary=True, min_df=2), 'citations'),\n",
    "#      ('similar_patents', CountVectorizer(analyzer=iden, binary=True, min_df=2), 'similar_patents'),\n",
    "#      ('cpc', CountVectorizer(analyzer=cpc_split, binary=True, min_df=2), 'cpc_codes'),\n",
    "#      ('embedding_v1', Extract(), 'embedding_v1'),\n",
    "     ('usif_abstract', Embedder(usif), 'abstract'),\n",
    "     ('usif_claims', Embedder(usif), 'claims'),\n",
    "     ('usif_description', Embedder(usif), 'description'),\n",
    "#      ('abstract_tfidf', TfidfVectorizer(**tfidf_default_settings), 'abstract'),\n",
    "#      ('claims_tfidf', TfidfVectorizer(**tfidf_default_settings), 'claims'),\n",
    "#      ('description_tfidf', TfidfVectorizer(**tfidf_default_settings), 'description')\n",
    "    ], verbose=False, n_jobs=-1)\n",
    "\n",
    "\n",
    "\n",
    "transformer_grid = {\n",
    "#     'top_terms__min_df': (1, 5),\n",
    "#     'top_terms__max_df': Real(0.1, 1.0),\n",
    "#     'cited_by__min_df': (1, 5),\n",
    "#     'cited_by__max_df': Real(0.1, 1.0),\n",
    "#     'inventors__min_df': (1, 20),\n",
    "#     'inventors__max_df': Real(0.1, 1.0),\n",
    "#     'citations__min_df': (1, 20),\n",
    "#     'citations__max_df': Real(0.1, 1.0),\n",
    "#     'similar_patents__min_df': (1, 20),\n",
    "#     'similar_patents__max_df': Real(0.1, 1.0),\n",
    "#     'cpc__min_df': (1, 20),\n",
    "#     'cpc__max_df': Real(0.1, 1.0),\n",
    "#     'abstract_tfidf__min_df': (1, 20),\n",
    "#     'abstract_tfidf__max_df': Real(0.1, 1.0),\n",
    "#     'claims_tfidf__min_df': (1, 20),\n",
    "#     'claims_tfidf__max_df': Real(0.1, 1.0),\n",
    "#     'description_tfidf__min_df': (1, 20),\n",
    "#     'description_tfidf__max_df': Real(0.1, 1.0),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('transformer', transformer),\n",
    "                       #('svd', TruncatedSVD(random_state=42, n_components=1024)),\n",
    "                       #('dummy', OneVsRestClassifier(DummyClassifier()))\n",
    "                       #('svc', OneVsRestClassifier(SVC(random_state=42), n_jobs=-1))\n",
    "                       ('rf',  RandomForestClassifier(n_jobs=-1, random_state=42))\n",
    "                       #('lr', OneVsRestClassifier(LogisticRegression(n_jobs=-1), n_jobs=-1))\n",
    "                       #('cat', OneVsRestClassifier(CatBoostClassifier(verbose=True)))\n",
    "                       #('knn', KNeighborsClassifier(n_jobs=-1))\n",
    "                      ], \n",
    "                verbose=True,\n",
    "                memory=\"cachedir/\")\n",
    "\n",
    "model_grid = {\n",
    "    'svd__n_components': (8, 1024),\n",
    "    'rf__max_depth': (1, 500), #[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 125, 150, 175, 200, 250, 300, 350, 400, None],\n",
    "    'rf__min_samples_leaf': (1, 12),\n",
    "    'rf__min_samples_split': (2, 12),\n",
    "    'rf__n_estimators': (5, 10000)          \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ....... (step 1 of 2) Processing transformer, total=  37.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/anaconda3/envs/phenetics/lib/python3.8/site-packages/sklearn/pipeline.py:309: UserWarning: Persisting input arguments took 91.09s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ................ (step 2 of 2) Processing rf, total=   0.3s\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Manufacturing       0.39      0.27      0.31        83\n",
      " SpecificationofUse       0.42      0.20      0.27        79\n",
      "            Imaging       0.59      0.65      0.62       133\n",
      "AnalysisAndModeling       0.47      0.20      0.28        84\n",
      "     SurgicalMethod       0.86      0.15      0.26        40\n",
      "   AnatomicalTarget       0.71      0.83      0.76       164\n",
      "\n",
      "          micro avg       0.59      0.49      0.53       583\n",
      "          macro avg       0.57      0.38      0.42       583\n",
      "       weighted avg       0.57      0.49      0.50       583\n",
      "        samples avg       0.60      0.50      0.51       583\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/anaconda3/envs/phenetics/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/martin/anaconda3/envs/phenetics/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(training_set, training_labels)\n",
    "predictions = pipe.predict(testing_set)\n",
    "print(classification_report(testing_labels, predictions, target_names=subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {**model_grid, **({f\"transformer__{k}\": v for k,v in transformer_grid.items()})}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = BayesSearchCV(pipe, param_grid, n_iter=50, n_points=3, pre_dispatch=36, refit=True, cv=3, verbose=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "with tqdm(total=search.total_iterations) as pbar:\n",
    "    def on_step(optim_result):\n",
    "        print(optim_result)\n",
    "        pbar.update(9)\n",
    "        return False\n",
    "    search.fit(training_set, training_labels, callback=on_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions =  search.best_estimator_.predict(testing_set)\n",
    "print(classification_report(testing_labels, predictions, target_names=subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OrderedDict([('rf__max_depth', 10), ('rf__min_samples_leaf', 1), ('rf__min_samples_split', 12), ('rf__n_estimators', 1000), ('svd__n_components', 64)])\n",
    "\n",
    "                     precision    recall  f1-score   support\n",
    "\n",
    "            Imaging       0.59      0.90      0.71       133\n",
    "     SurgicalMethod       0.86      0.15      0.26        40\n",
    "AnalysisAndModeling       0.00      0.00      0.00        84\n",
    " SpecificationofUse       0.64      0.09      0.16        79\n",
    "   AnatomicalTarget       0.69      0.96      0.80       164\n",
    "      Manufacturing       0.48      0.13      0.21        83\n",
    "\n",
    "          micro avg       0.63      0.52      0.57       583\n",
    "          macro avg       0.54      0.37      0.35       583\n",
    "       weighted avg       0.54      0.52      0.46       583\n",
    "        samples avg       0.64      0.55      0.55       583"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuned RF with uSIF (Glove)\n",
    "\n",
    "#      SurgicalMethod       1.00      0.03      0.05        40\n",
    "#    AnatomicalTarget       0.68      0.95      0.79       164\n",
    "#             Imaging       0.55      0.78      0.64       133\n",
    "#  SpecificationofUse       0.50      0.04      0.07        79\n",
    "# AnalysisAndModeling       0.20      0.01      0.02        84\n",
    "#       Manufacturing       0.57      0.10      0.16        83\n",
    "\n",
    "#           micro avg       0.61      0.47      0.53       583\n",
    "#           macro avg       0.58      0.32      0.29       583\n",
    "#        weighted avg       0.56      0.47      0.41       583\n",
    "#         samples avg       0.63      0.50      0.52       583"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
